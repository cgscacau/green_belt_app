import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from typing import Dict, List
from src.utils.project_manager import ProjectManager, DataSyncManager
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def show_data_collection_plan(project_data: Dict):
    """Plano de Coleta de Dados"""
    
    project_id = project_data.get('id')
    project_manager = ProjectManager()
    
    st.markdown("## üìä Plano de Coleta de Dados")
    st.markdown("Defina **o que**, **como**, **quando** e **onde** coletar os dados do processo.")
    
    # Inicializar dados
    plan_key = f"data_plan_{project_id}"
    if plan_key not in st.session_state:
        existing_data = project_data.get('measure', {}).get('data_collection_plan', {}).get('data', {})
        st.session_state[plan_key] = existing_data if existing_data else {}
    
    plan_data = st.session_state[plan_key]
    
    # Status atual
    is_completed = project_data.get('measure', {}).get('data_collection_plan', {}).get('completed', False)
    if is_completed:
        st.success("‚úÖ Plano de coleta finalizado")
    else:
        st.info("‚è≥ Plano em desenvolvimento")
    
    # Objetivo da coleta
    st.markdown("### üéØ Objetivo da Coleta")
    collection_objective = st.text_area(
        "Objetivo Principal da Coleta *",
        value=plan_data.get('collection_objective', ''),
        placeholder="Ex: Medir a variabilidade do tempo de setup das m√°quinas...",
        height=80,
        key=f"collection_objective_{project_id}"
    )
    
    # Vari√°veis a medir
    st.markdown("### üìè Vari√°veis a Medir")
    
    if 'variables' not in plan_data:
        plan_data['variables'] = []
    
    # Adicionar vari√°vel
    with st.expander("‚ûï Adicionar Vari√°vel"):
        col1, col2 = st.columns(2)
        with col1:
            var_name = st.text_input("Nome da Vari√°vel", key=f"var_name_{project_id}")
            var_type = st.selectbox("Tipo", ["Cont√≠nua", "Discreta", "Categ√≥rica"], key=f"var_type_{project_id}")
        with col2:
            var_unit = st.text_input("Unidade", key=f"var_unit_{project_id}")
            var_target = st.text_input("Meta", key=f"var_target_{project_id}")
        
        if st.button("‚ûï Adicionar", key=f"add_var_{project_id}"):
            if var_name.strip():
                plan_data['variables'].append({
                    'name': var_name.strip(),
                    'type': var_type,
                    'unit': var_unit,
                    'target': var_target
                })
                st.session_state[plan_key] = plan_data
                st.rerun()
    
    # Mostrar vari√°veis
    if plan_data['variables']:
        for i, var in enumerate(plan_data['variables']):
            col1, col2 = st.columns([4, 1])
            with col1:
                st.write(f"**{var['name']}** ({var['type']}) - {var['unit']} - Meta: {var['target']}")
            with col2:
                if st.button("üóëÔ∏è", key=f"remove_var_{i}_{project_id}"):
                    plan_data['variables'].pop(i)
                    st.session_state[plan_key] = plan_data
                    st.rerun()
    
    # M√©todo e cronograma
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### üîß M√©todo de Coleta")
        collection_method = st.selectbox(
            "M√©todo Principal",
            ["Medi√ß√£o Direta", "Observa√ß√£o", "Sistema Automatizado", "Formul√°rio"],
            key=f"collection_method_{project_id}"
        )
        responsible_person = st.text_input(
            "Respons√°vel",
            value=plan_data.get('responsible_person', ''),
            key=f"responsible_person_{project_id}"
        )
    
    with col2:
        st.markdown("### üìÖ Cronograma")
        start_date = st.date_input("Data In√≠cio", key=f"start_date_{project_id}")
        sample_size = st.number_input("Tamanho da Amostra", value=30, min_value=1, key=f"sample_size_{project_id}")
    
    # Bot√µes
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üíæ Salvar", key=f"save_plan_{project_id}"):
            _save_tool_data(project_id, 'data_collection_plan', {
                'collection_objective': collection_objective,
                'variables': plan_data['variables'],
                'collection_method': collection_method,
                'responsible_person': responsible_person,
                'start_date': start_date.isoformat(),
                'sample_size': sample_size
            }, False)
            st.success("üíæ Salvo!")
    
    with col2:
        if st.button("‚úÖ Finalizar", key=f"complete_plan_{project_id}"):
            if collection_objective.strip() and plan_data['variables'] and responsible_person.strip():
                _save_tool_data(project_id, 'data_collection_plan', {
                    'collection_objective': collection_objective,
                    'variables': plan_data['variables'],
                    'collection_method': collection_method,
                    'responsible_person': responsible_person,
                    'start_date': start_date.isoformat(),
                    'sample_size': sample_size
                }, True)
                st.success("‚úÖ Finalizado!")
                st.balloons()
            else:
                st.error("‚ùå Preencha todos os campos obrigat√≥rios")


def show_file_upload_analysis(project_data: Dict):
    """Upload e An√°lise de Dados - VERS√ÉO INTEGRADA COM FIREBASE"""
    
    project_id = project_data.get('id')
    project_manager = ProjectManager()
    sync_manager = DataSyncManager(project_id)
    
    st.markdown("## üìÅ Upload e An√°lise de Dados")
    st.markdown("Fa√ßa upload dos dados do processo para an√°lise estat√≠stica.")
    
    # Verificar se j√° existem dados carregados
    existing_data = project_manager.get_uploaded_data(project_id)
    upload_info = project_manager.get_upload_info(project_id)
    
    # Status do upload
    is_completed = project_data.get('measure', {}).get('file_upload', {}).get('completed', False)
    
    if existing_data is not None and is_completed:
        st.success("‚úÖ **Dados j√° carregados e salvos no projeto**")
        
        # Mostrar informa√ß√µes do arquivo atual
        if upload_info:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("üìÑ Arquivo", upload_info.get('filename', 'N/A'))
            
            with col2:
                shape = upload_info.get('shape', [0, 0])
                st.metric("üìä Dimens√µes", f"{shape[0]} √ó {shape[1]}")
            
            with col3:
                st.metric("üìà Colunas Num√©ricas", upload_info.get('data_summary', {}).get('numeric_columns', 0))
            
            with col4:
                upload_date = upload_info.get('uploaded_at', '')[:10] if upload_info.get('uploaded_at') else 'N/A'
                st.metric("üìÖ Upload", upload_date)
        
        # Op√ß√£o para substituir dados
        if st.checkbox("üîÑ Substituir dados existentes", key=f"replace_data_{project_id}"):
            st.warning("‚ö†Ô∏è **Aten√ß√£o:** Isso substituir√° os dados atuais e pode afetar an√°lises j√° realizadas.")
            show_upload_interface = True
        else:
            show_upload_interface = False
            # Mostrar dados existentes
            _show_data_analysis(existing_data, project_id, upload_info)
    else:
        show_upload_interface = True
    
    # Interface de upload
    if show_upload_interface:
        st.markdown("### üì§ Upload de Arquivo")
        
        # Upload
        uploaded_file = st.file_uploader(
            "Escolha um arquivo de dados",
            type=['csv', 'xlsx', 'xls'],
            key=f"file_upload_{project_id}",
            help="Formatos suportados: CSV, Excel (.xlsx, .xls)"
        )
        
        if uploaded_file is not None:
            try:
                with st.spinner("Processando arquivo..."):
                    # Ler arquivo
                    if uploaded_file.name.endswith('.csv'):
                        # Tentar diferentes encodings para CSV
                        encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
                        df = None
                        
                        for encoding in encodings:
                            try:
                                df = pd.read_csv(uploaded_file, encoding=encoding)
                                break
                            except UnicodeDecodeError:
                                continue
                        
                        if df is None:
                            st.error("‚ùå Erro de codifica√ß√£o. Tente salvar o CSV em UTF-8.")
                            return
                    else:
                        df = pd.read_excel(uploaded_file)
                
                # Valida√ß√µes b√°sicas
                if df.empty:
                    st.error("‚ùå Arquivo vazio")
                    return
                
                if len(df.columns) == 0:
                    st.error("‚ùå Nenhuma coluna encontrada")
                    return
                
                # Salvar usando o ProjectManager
                success = project_manager.save_uploaded_data(
                    project_id=project_id,
                    dataframe=df,
                    filename=uploaded_file.name,
                    additional_info={
                        'file_size': uploaded_file.size,
                        'upload_method': 'streamlit_uploader'
                    }
                )
                
                if success:
                    st.success(f"‚úÖ **Arquivo carregado com sucesso:** {uploaded_file.name}")
                    
                    # Mostrar informa√ß√µes b√°sicas
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("üìä Linhas", df.shape[0])
                    
                    with col2:
                        st.metric("üìã Colunas", df.shape[1])
                    
                    with col3:
                        numeric_cols = len(df.select_dtypes(include=[np.number]).columns)
                        st.metric("üìà Num√©ricas", numeric_cols)
                    
                    with col4:
                        categorical_cols = len(df.select_dtypes(include=['object']).columns)
                        st.metric("üìù Categ√≥ricas", categorical_cols)
                    
                    # Mostrar an√°lise dos dados
                    _show_data_analysis(df, project_id, project_manager.get_upload_info(project_id))
                    
                    # Rerun para atualizar a interface
                    st.rerun()
                else:
                    st.error("‚ùå Erro ao salvar dados no projeto")
                
            except Exception as e:
                st.error(f"‚ùå Erro ao processar arquivo: {str(e)}")
                st.info("üí° **Dicas:**")
                st.write("‚Ä¢ Verifique se o arquivo n√£o est√° corrompido")
                st.write("‚Ä¢ Para CSV, tente salvar com codifica√ß√£o UTF-8")
                st.write("‚Ä¢ Verifique se h√° caracteres especiais nos nomes das colunas")


def _show_data_analysis(df: pd.DataFrame, project_id: str, upload_info: Dict = None):
    """Mostra an√°lise dos dados carregados"""
    
    st.markdown("### üìä An√°lise dos Dados Carregados")
    
    # Verifica√ß√µes de qualidade dos dados
    _show_data_quality_check(df)
    
    # Tabs para diferentes visualiza√ß√µes
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üëÄ Visualiza√ß√£o", 
        "üìà Estat√≠sticas", 
        "üìä Gr√°ficos", 
        "üîç Qualidade",
        "üíæ A√ß√µes"
    ])
    
    with tab1:
        st.markdown("#### üìã Primeiras 10 linhas")
        st.dataframe(df.head(10), use_container_width=True)
        
        if len(df) > 10:
            st.info(f"üí° Mostrando 10 de {len(df)} linhas. Use as outras abas para an√°lise completa.")
        
        # Informa√ß√µes sobre colunas
        st.markdown("#### üìä Informa√ß√µes das Colunas")
        
        col_info = []
        for col in df.columns:
            col_data = df[col]
            col_info.append({
                'Coluna': col,
                'Tipo': str(col_data.dtype),
                'N√£o Nulos': col_data.count(),
                'Nulos': col_data.isnull().sum(),
                '% Nulos': f"{(col_data.isnull().sum() / len(df) * 100):.1f}%",
                '√önicos': col_data.nunique()
            })
        
        col_info_df = pd.DataFrame(col_info)
        st.dataframe(col_info_df, use_container_width=True)
    
    with tab2:
        st.markdown("#### üìà Estat√≠sticas Descritivas")
        
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
        
        if numeric_columns:
            st.markdown("**Vari√°veis Num√©ricas:**")
            
            # Sele√ß√£o de colunas para an√°lise
            selected_numeric = st.multiselect(
                "Selecione colunas num√©ricas:",
                numeric_columns,
                default=numeric_columns[:5],  # M√°ximo 5 para n√£o sobrecarregar
                key=f"selected_numeric_{project_id}"
            )
            
            if selected_numeric:
                desc_stats = df[selected_numeric].describe()
                st.dataframe(desc_stats, use_container_width=True)
                
                # Estat√≠sticas adicionais
                st.markdown("**Estat√≠sticas Adicionais:**")
                additional_stats = []
                
                for col in selected_numeric:
                    col_data = df[col].dropna()
                    if len(col_data) > 0:
                        additional_stats.append({
                            'Coluna': col,
                            'Assimetria': stats.skew(col_data),
                            'Curtose': stats.kurtosis(col_data),
                            'CV (%)': (col_data.std() / col_data.mean() * 100) if col_data.mean() != 0 else 0
                        })
                
                if additional_stats:
                    st.dataframe(pd.DataFrame(additional_stats), use_container_width=True)
        else:
            st.info("üìä Nenhuma coluna num√©rica encontrada")
        
        if categorical_columns:
            st.markdown("**Vari√°veis Categ√≥ricas:**")
            
            selected_categorical = st.selectbox(
                "Selecione uma coluna categ√≥rica:",
                categorical_columns,
                key=f"selected_categorical_{project_id}"
            )
            
            if selected_categorical:
                value_counts = df[selected_categorical].value_counts()
                st.write(f"**Distribui√ß√£o de {selected_categorical}:**")
                
                # Criar DataFrame para melhor visualiza√ß√£o
                freq_df = pd.DataFrame({
                    'Valor': value_counts.index,
                    'Frequ√™ncia': value_counts.values,
                    'Percentual': (value_counts.values / len(df) * 100).round(1)
                })
                
                st.dataframe(freq_df, use_container_width=True)
    
    with tab3:
        st.markdown("#### üìä Visualiza√ß√µes")
        
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if not numeric_columns:
            st.warning("‚ö†Ô∏è Nenhuma coluna num√©rica para gr√°ficos")
            return
        
        # Tipo de gr√°fico
        chart_type = st.selectbox(
            "Tipo de Gr√°fico:",
            ["Histograma", "Box Plot", "Scatter Plot", "Correla√ß√£o", "S√©rie Temporal"],
            key=f"chart_type_{project_id}"
        )
        
        if chart_type == "Histograma":
            col_to_plot = st.selectbox("Coluna:", numeric_columns, key=f"hist_col_{project_id}")
            
            bins = st.slider("N√∫mero de bins:", 10, 100, 30, key=f"hist_bins_{project_id}")
            
            fig = px.histogram(df, x=col_to_plot, nbins=bins, title=f"Histograma - {col_to_plot}")
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
        
        elif chart_type == "Box Plot":
            cols_to_plot = st.multiselect(
                "Colunas:", 
                numeric_columns, 
                default=numeric_columns[:3],
                key=f"box_cols_{project_id}"
            )
            
            if cols_to_plot:
                fig = go.Figure()
                for col in cols_to_plot:
                    fig.add_trace(go.Box(y=df[col], name=col))
                
                fig.update_layout(title="Box Plot Comparativo", height=500)
                st.plotly_chart(fig, use_container_width=True)
        
        elif chart_type == "Scatter Plot":
            if len(numeric_columns) >= 2:
                col1, col2 = st.columns(2)
                
                with col1:
                    x_col = st.selectbox("Eixo X:", numeric_columns, key=f"scatter_x_{project_id}")
                
                with col2:
                    y_options = [col for col in numeric_columns if col != x_col]
                    y_col = st.selectbox("Eixo Y:", y_options, key=f"scatter_y_{project_id}")
                
                fig = px.scatter(df, x=x_col, y=y_col, title=f"Scatter: {x_col} vs {y_col}")
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Necess√°rio pelo menos 2 colunas num√©ricas")
        
        elif chart_type == "Correla√ß√£o":
            if len(numeric_columns) >= 2:
                corr_cols = st.multiselect(
                    "Colunas para correla√ß√£o:",
                    numeric_columns,
                    default=numeric_columns[:5],
                    key=f"corr_cols_{project_id}"
                )
                
                if len(corr_cols) >= 2:
                    corr_matrix = df[corr_cols].corr()
                    
                    fig = px.imshow(
                        corr_matrix,
                        text_auto=True,
                        aspect="auto",
                        title="Matriz de Correla√ß√£o",
                        color_continuous_scale='RdBu_r'
                    )
                    fig.update_layout(height=500)
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Necess√°rio pelo menos 2 colunas num√©ricas")
        
        elif chart_type == "S√©rie Temporal":
            time_col = st.selectbox("Coluna para s√©rie temporal:", numeric_columns, key=f"time_col_{project_id}")
            
            fig = px.line(x=range(len(df)), y=df[time_col], title=f"S√©rie Temporal - {time_col}")
            fig.update_xaxes(title="Observa√ß√£o")
            fig.update_yaxes(title=time_col)
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.markdown("#### üîç An√°lise de Qualidade dos Dados")
        _show_detailed_quality_analysis(df)
    
    with tab5:
        st.markdown("#### üíæ A√ß√µes com os Dados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Download dos dados processados
            if st.button("üì• Download CSV", key=f"download_csv_{project_id}"):
                csv = df.to_csv(index=False)
                st.download_button(
                    label="üì• Baixar arquivo CSV",
                    data=csv,
                    file_name=f"dados_processados_{project_id}.csv",
                    mime="text/csv"
                )
        
        with col2:
            # Informa√ß√µes sobre o upload
            if upload_info:
                st.info(f"üìÑ **Arquivo original:** {upload_info.get('filename', 'N/A')}")
                st.info(f"üìÖ **Data do upload:** {upload_info.get('uploaded_at', 'N/A')[:19]}")


def _show_data_quality_check(df: pd.DataFrame):
    """Verifica√ß√£o r√°pida da qualidade dos dados"""
    
    # M√©tricas de qualidade
    total_cells = df.shape[0] * df.shape[1]
    missing_cells = df.isnull().sum().sum()
    missing_percentage = (missing_cells / total_cells) * 100
    
    # Duplicatas
    duplicates = df.duplicated().sum()
    duplicate_percentage = (duplicates / len(df)) * 100
    
    # Status geral
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if missing_percentage < 5:
            st.success(f"‚úÖ Dados Faltantes: {missing_percentage:.1f}%")
        elif missing_percentage < 15:
            st.warning(f"‚ö†Ô∏è Dados Faltantes: {missing_percentage:.1f}%")
        else:
            st.error(f"‚ùå Dados Faltantes: {missing_percentage:.1f}%")
    
    with col2:
        if duplicate_percentage < 1:
            st.success(f"‚úÖ Duplicatas: {duplicate_percentage:.1f}%")
        elif duplicate_percentage < 5:
            st.warning(f"‚ö†Ô∏è Duplicatas: {duplicate_percentage:.1f}%")
        else:
            st.error(f"‚ùå Duplicatas: {duplicate_percentage:.1f}%")
    
    with col3:
        numeric_cols = len(df.select_dtypes(include=[np.number]).columns)
        if numeric_cols > 0:
            st.success(f"‚úÖ Colunas Num√©ricas: {numeric_cols}")
        else:
            st.warning("‚ö†Ô∏è Nenhuma coluna num√©rica")
    
    with col4:
        if len(df) >= 30:
            st.success(f"‚úÖ Amostra: {len(df)} registros")
        elif len(df) >= 10:
            st.warning(f"‚ö†Ô∏è Amostra pequena: {len(df)}")
        else:
            st.error(f"‚ùå Amostra muito pequena: {len(df)}")


def _show_detailed_quality_analysis(df: pd.DataFrame):
    """An√°lise detalhada da qualidade dos dados"""
    
    st.markdown("##### üìä Resumo de Qualidade")
    
    quality_issues = []
    
    # An√°lise por coluna
    for col in df.columns:
        col_data = df[col]
        issues = []
        
        # Dados faltantes
        missing_pct = (col_data.isnull().sum() / len(df)) * 100
        if missing_pct > 10:
            issues.append(f"Dados faltantes: {missing_pct:.1f}%")
        
        # Valores √∫nicos (poss√≠vel problema de cardinalidade)
        unique_pct = (col_data.nunique() / len(df)) * 100
        if unique_pct > 95:
            issues.append("Alta cardinalidade (poss√≠vel ID)")
        elif unique_pct < 5 and col_data.dtype == 'object':
            issues.append("Baixa cardinalidade")
        
        # Para colunas num√©ricas
        if pd.api.types.is_numeric_dtype(col_data):
            # Outliers usando IQR
            Q1 = col_data.quantile(0.25)
            Q3 = col_data.quantile(0.75)
            IQR = Q3 - Q1
            
            if IQR > 0:
                outliers = col_data[(col_data < Q1 - 1.5 * IQR) | (col_data > Q3 + 1.5 * IQR)]
                outlier_pct = (len(outliers) / len(col_data.dropna())) * 100
                
                if outlier_pct > 5:
                    issues.append(f"Outliers: {outlier_pct:.1f}%")
        
        if issues:
            quality_issues.append({
                'Coluna': col,
                'Problemas': '; '.join(issues)
            })
    
    if quality_issues:
        st.markdown("**‚ö†Ô∏è Problemas de Qualidade Identificados:**")
        quality_df = pd.DataFrame(quality_issues)
        st.dataframe(quality_df, use_container_width=True)
    else:
        st.success("‚úÖ Nenhum problema significativo de qualidade identificado")
    
    # Recomenda√ß√µes
    st.markdown("##### üí° Recomenda√ß√µes")
    
    recommendations = []
    
    missing_cols = [col for col in df.columns if df[col].isnull().sum() > 0]
    if missing_cols:
        recommendations.append("üîß **Dados faltantes:** Considere estrat√©gias de imputa√ß√£o ou remo√ß√£o")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        recommendations.append("üìä **An√°lise estat√≠stica:** Dados num√©ricos dispon√≠veis para an√°lise avan√ßada")
    
    if df.duplicated().sum() > 0:
        recommendations.append("üßπ **Duplicatas:** Remova registros duplicados se n√£o forem intencionais")
    
    if len(df) < 30:
        recommendations.append("‚ö†Ô∏è **Amostra pequena:** Considere coletar mais dados para an√°lises robustas")
    
    for rec in recommendations:
        st.write(rec)


def show_process_capability(project_data: Dict):
    """An√°lise de Capacidade do Processo - VERS√ÉO MELHORADA"""
    
    project_id = project_data.get('id')
    project_manager = ProjectManager()
    
    st.markdown("## üìê An√°lise de Capacidade do Processo")
    st.markdown("Avalie se o processo √© capaz de atender √†s especifica√ß√µes definidas.")
    
    # Verificar se h√° dados
    df = project_manager.get_uploaded_data(project_id)
    
    if df is None:
        st.warning("‚ö†Ô∏è **Dados n√£o encontrados**")
        st.info("Primeiro fa√ßa upload dos dados na ferramenta **Upload e An√°lise de Dados**")
        
        if st.button("üìÅ Ir para Upload de Dados", key=f"goto_upload_{project_id}"):
            st.rerun()
        return
    
    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_columns:
        st.error("‚ùå Nenhuma coluna num√©rica encontrada nos dados")
        return
    
    # Status
    is_completed = project_data.get('measure', {}).get('process_capability', {}).get('completed', False)
    if is_completed:
        st.success("‚úÖ An√°lise de capacidade finalizada")
    else:
        st.info("‚è≥ An√°lise em desenvolvimento")
    
    # Configura√ß√£o da an√°lise
    st.markdown("### ‚öôÔ∏è Configura√ß√£o da An√°lise")
    
    col1, col2 = st.columns(2)
    
    with col1:
        selected_column = st.selectbox(
            "Vari√°vel para an√°lise:",
            numeric_columns,
            key=f"cap_col_{project_id}",
            help="Selecione a vari√°vel cr√≠tica para qualidade (CTQ)"
        )
    
    with col2:
        spec_type = st.selectbox(
            "Tipo de Especifica√ß√£o:",
            ["Bilateral", "Superior apenas", "Inferior apenas"],
            key=f"spec_type_{project_id}",
            help="Bilateral: LSL e USL | Superior: apenas USL | Inferior: apenas LSL"
        )
    
    # Dados da vari√°vel selecionada
    data_col = df[selected_column].dropna()
    
    if len(data_col) == 0:
        st.error("‚ùå Coluna selecionada n√£o possui dados v√°lidos")
        return
    
    # Estat√≠sticas b√°sicas
    mean_val = data_col.mean()
    std_val = data_col.std()
    
    st.markdown("### üìä Estat√≠sticas da Vari√°vel")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("M√©dia", f"{mean_val:.4f}")
    
    with col2:
        st.metric("Desvio Padr√£o", f"{std_val:.4f}")
    
    with col3:
        st.metric("M√≠nimo", f"{data_col.min():.4f}")
    
    with col4:
        st.metric("M√°ximo", f"{data_col.max():.4f}")
    
    # Defini√ß√£o dos limites de especifica√ß√£o
    st.markdown("### üéØ Limites de Especifica√ß√£o")
    
    col3, col4 = st.columns(2)
    
    with col3:
        if spec_type in ["Bilateral", "Inferior apenas"]:
            lsl = st.number_input(
                "LSL (Limite Superior de Especifica√ß√£o):",
                value=float(mean_val - 3*std_val),
                key=f"lsl_{project_id}",
                help="Valor m√≠nimo aceit√°vel"
            )
        else:
            lsl = None
    
    with col4:
        if spec_type in ["Bilateral", "Superior apenas"]:
            usl = st.number_input(
                "USL (Limite Superior de Especifica√ß√£o):",
                value=float(mean_val + 3*std_val),
                key=f"usl_{project_id}",
                help="Valor m√°ximo aceit√°vel"
            )
        else:
            usl = None
    
    # Executar an√°lise
    if st.button("üîç Analisar Capacidade", key=f"analyze_cap_{project_id}", type="primary"):
        
        with st.spinner("Calculando √≠ndices de capacidade..."):
            # Calcular √≠ndices
            results = _calculate_capability_advanced(data_col, lsl, usl)
            
            # Mostrar resultados principais
            st.markdown("### üìà Resultados da An√°lise")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                if results['Cp'] is not None:
                    st.metric("Cp (Capacidade Potencial)", f"{results['Cp']:.3f}")
                else:
                    st.metric("Cp", "N/A")
            
            with col2:
                if results['Cpk'] is not None:
                    st.metric("Cpk (Capacidade Real)", f"{results['Cpk']:.3f}")
                else:
                    st.metric("Cpk", "N/A")
            
            with col3:
                if results['Pp'] is not None:
                    st.metric("Pp (Performance Potencial)", f"{results['Pp']:.3f}")
                else:
                    st.metric("Pp", "N/A")
            
            with col4:
                if results['Ppk'] is not None:
                    st.metric("Ppk (Performance Real)", f"{results['Ppk']:.3f}")
                else:
                    st.metric("Ppk", "N/A")
            
            # Interpreta√ß√£o dos resultados
            st.markdown("### üéØ Interpreta√ß√£o dos Resultados")
            
            if results['Cpk'] is not None:
                cpk_value = results['Cpk']
                
                if cpk_value >= 2.0:
                    st.success("üü¢ **Excelente:** Processo altamente capaz (Cpk ‚â• 2.0)")
                    capability_status = "Excelente"
                elif cpk_value >= 1.33:
                    st.success("üü¢ **Capaz:** Processo capaz (1.33 ‚â§ Cpk < 2.0)")
                    capability_status = "Capaz"
                elif cpk_value >= 1.0:
                    st.warning("üü° **Marginal:** Processo marginalmente capaz (1.0 ‚â§ Cpk < 1.33)")
                    capability_status = "Marginal"
                else:
                    st.error("üî¥ **N√£o Capaz:** Processo n√£o capaz (Cpk < 1.0)")
                    capability_status = "N√£o Capaz"
            else:
                capability_status = "Indeterminado"
            
            # Gr√°fico de capacidade
            st.markdown("### üìä Visualiza√ß√£o da Capacidade")
            
            fig = go.Figure()
            
            # Histograma dos dados
            fig.add_trace(go.Histogram(
                x=data_col,
                nbinsx=30,
                name="Distribui√ß√£o dos Dados",
                opacity=0.7,
                marker_color='lightblue'
            ))
            
            # Curva normal te√≥rica
            x_range = np.linspace(data_col.min(), data_col.max(), 100)
            normal_curve = stats.norm.pdf(x_range, mean_val, std_val) * len(data_col) * (data_col.max() - data_col.min()) / 30
            
            fig.add_trace(go.Scatter(
                x=x_range,
                y=normal_curve,
                mode='lines',
                name='Distribui√ß√£o Normal',
                line=dict(color='blue', width=2)
            ))
            
            # Limites de especifica√ß√£o
            if lsl is not None:
                fig.add_vline(
                    x=lsl,
                    line_dash="dash",
                    line_color="red",
                    line_width=3,
                    annotation_text="LSL"
                )
            
            if usl is not None:
                fig.add_vline(
                    x=usl,
                    line_dash="dash",
                    line_color="red",
                    line_width=3,
                    annotation_text="USL"
                )
            
            # M√©dia do processo
            fig.add_vline(
                x=mean_val,
                line_dash="dot",
                line_color="green",
                line_width=2,
                annotation_text="M√©dia"
            )
            
            fig.update_layout(
                title=f"An√°lise de Capacidade - {selected_column}",
                xaxis_title=selected_column,
                yaxis_title="Frequ√™ncia",
                height=500,
                showlegend=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Estat√≠sticas detalhadas
            st.markdown("### üìã Estat√≠sticas Detalhadas")
            
            detailed_stats = {
                'M√©trica': ['M√©dia do Processo', 'Desvio Padr√£o', 'LSL', 'USL', 'Amplitude Spec.'],
                'Valor': [
                    f"{mean_val:.4f}",
                    f"{std_val:.4f}",
                    f"{lsl:.4f}" if lsl is not None else "N/A",
                    f"{usl:.4f}" if usl is not None else "N/A",
                    f"{usl - lsl:.4f}" if (lsl is not None and usl is not None) else "N/A"
                ]
            }
            
            if results['defect_rate'] is not None:
                detailed_stats['M√©trica'].extend(['Taxa de Defeitos', 'PPM Defeitos'])
                detailed_stats['Valor'].extend([
                    f"{results['defect_rate']:.4f}%",
                    f"{results['defect_rate'] * 10000:.0f}"
                ])
            
            st.dataframe(pd.DataFrame(detailed_stats), use_container_width=True)
            
            # Recomenda√ß√µes
            st.markdown("### üí° Recomenda√ß√µes")
            
            recommendations = []
            
            if results['Cpk'] is not None:
                if results['Cpk'] < 1.0:
                    recommendations.extend([
                        "üîß **Melhoria urgente necess√°ria** - Processo n√£o capaz",
                        "üìä **Reduzir variabilidade** do processo",
                        "üéØ **Centralizar processo** se m√©dia estiver deslocada"
                    ])
                elif results['Cpk'] < 1.33:
                    recommendations.extend([
                        "‚ö†Ô∏è **Monitoramento pr√≥ximo** recomendado",
                        "üìà **Considerar melhorias** para aumentar capacidade"
                    ])
                else:
                    recommendations.append("‚úÖ **Manter controle atual** - Processo capaz")
            
            if results['Cp'] is not None and results['Cpk'] is not None:
                if results['Cp'] > results['Cpk'] + 0.1:
                    recommendations.append("üéØ **Centralizar processo** - Cp >> Cpk indica descentramento")
            
            for rec in recommendations:
                st.write(rec)
            
            # Salvar resultados
            if st.button("üíæ Salvar An√°lise de Capacidade", key=f"save_cap_{project_id}"):
                cap_data = {
                    'variable': selected_column,
                    'spec_type': spec_type,
                    'lsl': float(lsl) if lsl is not None else None,
                    'usl': float(usl) if usl is not None else None,
                    'process_mean': float(mean_val),
                    'process_std': float(std_val),
                    'sample_size': int(len(data_col)),
                    'cp': float(results['Cp']) if results['Cp'] is not None else None,
                    'cpk': float(results['Cpk']) if results['Cpk'] is not None else None,
                    'pp': float(results['Pp']) if results['Pp'] is not None else None,
                    'ppk': float(results['Ppk']) if results['Ppk'] is not None else None,
                    'defect_rate': float(results['defect_rate']) if results['defect_rate'] is not None else None,
                    'capability_status': capability_status,
                    'analysis_date': datetime.now().isoformat()
                }
                
                success = _save_tool_data(project_id, 'process_capability', cap_data, True)
                if success:
                    st.success("‚úÖ An√°lise de capacidade salva com sucesso!")
                    st.balloons()


def _calculate_capability_advanced(data, lsl=None, usl=None):
    """Calcular √≠ndices de capacidade avan√ßados"""
    try:
        mean_val = data.mean()
        std_val = data.std()
        n = len(data)
        
        results = {
            'Cp': None, 'Cpk': None, 'Pp': None, 'Ppk': None,
            'defect_rate': None, 'sigma_level': None
        }
        
        # Cp e Cpk (baseados em desvio padr√£o within)
        if lsl is not None and usl is not None and std_val > 0:
            results['Cp'] = (usl - lsl) / (6 * std_val)
            cpu = (usl - mean_val) / (3 * std_val)
            cpl = (mean_val - lsl) / (3 * std_val)
            results['Cpk'] = min(cpu, cpl)
            
            # Pp e Ppk (baseados em desvio padr√£o total)
            results['Pp'] = (usl - lsl) / (6 * std_val)
            results['Ppk'] = results['Cpk']  # Simplificado
            
        elif usl is not None and std_val > 0:
            results['Cpk'] = (usl - mean_val) / (3 * std_val)
            results['Ppk'] = results['Cpk']
            
        elif lsl is not None and std_val > 0:
            results['Cpk'] = (mean_val - lsl) / (3 * std_val)
            results['Ppk'] = results['Cpk']
        
        # Taxa de defeitos
        if lsl is not None or usl is not None:
            defects = 0
            
            if lsl is not None:
                defects += sum(data < lsl)
            
            if usl is not None:
                defects += sum(data > usl)
            
            results['defect_rate'] = (defects / len(data)) * 100
        
        return results
        
    except Exception as e:
        st.error(f"Erro no c√°lculo: {str(e)}")
        return {'Cp': None, 'Cpk': None, 'Pp': None, 'Ppk': None, 'defect_rate': None}


# Manter as outras fun√ß√µes (MSA, baseline) como estavam
def show_msa_analysis(project_data: Dict):
    """MSA - An√°lise do Sistema de Medi√ß√£o - VERS√ÉO SIMPLIFICADA"""
    
    project_id = project_data.get('id')
    
    st.markdown("## üéØ MSA - Sistema de Medi√ß√£o")
    
    st.info("""
    **MSA (Measurement System Analysis)**
    
    Avalia a qualidade do sistema de medi√ß√£o atrav√©s de:
    - **Repetibilidade**: Varia√ß√£o do mesmo operador
    - **Reprodutibilidade**: Varia√ß√£o entre operadores
    - **R&R**: Combina√ß√£o de ambos
    """)
    
    # Configura√ß√£o b√°sica
    col1, col2, col3 = st.columns(3)
    with col1:
        num_operators = st.number_input("Operadores", min_value=2, max_value=5, value=3, key=f"ops_{project_id}")
    with col2:
        num_parts = st.number_input("Pe√ßas", min_value=5, max_value=20, value=10, key=f"parts_{project_id}")
    with col3:
        num_trials = st.number_input("Repeti√ß√µes", min_value=2, max_value=5, value=3, key=f"trials_{project_id}")
    
    # Gerar template
    if st.button("üì• Gerar Template MSA", key=f"gen_template_{project_id}"):
        template_data = []
        for op in range(1, num_operators + 1):
            for part in range(1, num_parts + 1):
                for trial in range(1, num_trials + 1):
                    template_data.append({
                        'Operador': f'Op_{op}',
                        'Pe√ßa': f'Pe√ßa_{part}',
                        'Repeti√ß√£o': trial,
                        'Medi√ß√£o': ''
                    })
        
        template_df = pd.DataFrame(template_data)
        st.dataframe(template_df.head(15))
        
        csv = template_df.to_csv(index=False)
        st.download_button(
            "üì• Download Template",
            csv,
            f"MSA_Template_{project_data.get('name', 'Projeto')}.csv",
            "text/csv"
        )
    
    # Upload MSA
    msa_file = st.file_uploader("Upload dados MSA", type=['csv', 'xlsx'], key=f"msa_upload_{project_id}")
    
    if msa_file:
        try:
            if msa_file.name.endswith('.csv'):
                msa_df = pd.read_csv(msa_file)
            else:
                msa_df = pd.read_excel(msa_file)
            
            required_cols = ['Operador', 'Pe√ßa', 'Repeti√ß√£o', 'Medi√ß√£o']
            if all(col in msa_df.columns for col in required_cols):
                st.success(f"‚úÖ Dados MSA carregados: {len(msa_df)} medi√ß√µes")
                
                # An√°lise MSA simplificada
                try:
                    msa_df['Medi√ß√£o'] = pd.to_numeric(msa_df['Medi√ß√£o'], errors='coerce')
                    msa_df = msa_df.dropna(subset=['Medi√ß√£o'])
                    
                    # C√°lculo b√°sico de R&R
                    total_var = msa_df['Medi√ß√£o'].var()
                    part_var = msa_df.groupby('Pe√ßa')['Medi√ß√£o'].mean().var()
                    rr_var = total_var - part_var
                    
                    rr_percent = (rr_var / total_var) * 100 if total_var > 0 else 0
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("R&R (%)", f"{rr_percent:.1f}%")
                    with col2:
                        if rr_percent < 10:
                            st.success("‚úÖ Excelente")
                        elif rr_percent < 30:
                            st.warning("‚ö†Ô∏è Aceit√°vel")
                        else:
                            st.error("‚ùå Inadequado")
                    with col3:
                        st.metric("Medi√ß√µes", len(msa_df))
                    
                    # Salvar MSA
                    if st.button("üíæ Salvar MSA", key=f"save_msa_{project_id}"):
                        msa_data = {
                            'num_operators': num_operators,
                            'num_parts': num_parts,
                            'num_trials': num_trials,
                            'total_measurements': len(msa_df),
                            'rr_percent': float(rr_percent),
                            'interpretation': 'Excelente' if rr_percent < 10 else ('Aceit√°vel' if rr_percent < 30 else 'Inadequado'),
                            'analysis_date': datetime.now().isoformat()
                        }
                        
                        _save_tool_data(project_id, 'msa', msa_data, True)
                        st.success("‚úÖ MSA salvo!")
                        
                except Exception as e:
                    st.error(f"‚ùå Erro na an√°lise MSA: {str(e)}")
            else:
                st.error(f"‚ùå Colunas obrigat√≥rias: {required_cols}")
                
        except Exception as e:
            st.error(f"‚ùå Erro ao processar arquivo: {str(e)}")


def show_baseline_metrics(project_data: Dict):
    """Baseline e M√©tricas CTQ"""
    
    project_id = project_data.get('id')
    
    st.markdown("## üìà Baseline e M√©tricas CTQ")
    
    # Inicializar dados
    baseline_key = f"baseline_{project_id}"
    if baseline_key not in st.session_state:
        existing_data = project_data.get('measure', {}).get('baseline_data', {}).get('data', {})
        st.session_state[baseline_key] = existing_data if existing_data else {'ctq_metrics': []}
    
    baseline_data = st.session_state[baseline_key]
    
    # Status
    is_completed = project_data.get('measure', {}).get('baseline_data', {}).get('completed', False)
    if is_completed:
        st.success("‚úÖ Baseline finalizado")
    else:
        st.info("‚è≥ Baseline em desenvolvimento")
    
    # Adicionar CTQ
    st.markdown("### üéØ M√©tricas CTQ")
    
    with st.expander("‚ûï Adicionar M√©trica CTQ"):
        col1, col2 = st.columns(2)
        with col1:
            ctq_name = st.text_input("Nome da M√©trica", key=f"ctq_name_{project_id}")
            ctq_baseline = st.number_input("Valor Baseline", key=f"ctq_baseline_{project_id}")
        with col2:
            ctq_target = st.number_input("Meta", key=f"ctq_target_{project_id}")
            ctq_unit = st.text_input("Unidade", key=f"ctq_unit_{project_id}")
        
        if st.button("‚ûï Adicionar CTQ", key=f"add_ctq_{project_id}"):
            if ctq_name.strip():
                baseline_data['ctq_metrics'].append({
                    'name': ctq_name.strip(),
                    'baseline': ctq_baseline,
                    'target': ctq_target,
                    'unit': ctq_unit
                })
                st.session_state[baseline_key] = baseline_data
                st.rerun()
    
    # Mostrar CTQs
    if baseline_data['ctq_metrics']:
        for i, ctq in enumerate(baseline_data['ctq_metrics']):
            col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
            with col1:
                st.write(f"**{ctq['name']}**")
            with col2:
                st.write(f"Baseline: {ctq['baseline']} {ctq['unit']}")
            with col3:
                st.write(f"Meta: {ctq['target']} {ctq['unit']}")
            with col4:
                if st.button("üóëÔ∏è", key=f"remove_ctq_{i}_{project_id}"):
                    baseline_data['ctq_metrics'].pop(i)
                    st.session_state[baseline_key] = baseline_data
                    st.rerun()
    
    # Per√≠odo e fonte
    col1, col2 = st.columns(2)
    with col1:
        baseline_period = st.text_input(
            "Per√≠odo do Baseline",
            value=baseline_data.get('baseline_period', ''),
            key=f"baseline_period_{project_id}"
        )
    with col2:
        data_source = st.text_input(
            "Fonte dos Dados",
            value=baseline_data.get('data_source', ''),
            key=f"baseline_source_{project_id}"
        )
    
    # Bot√µes
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üíæ Salvar", key=f"save_baseline_{project_id}"):
            _save_tool_data(project_id, 'baseline_data', {
                'ctq_metrics': baseline_data['ctq_metrics'],
                'baseline_period': baseline_period,
                'data_source': data_source
            }, False)
            st.success("üíæ Salvo!")
    
    with col2:
        if st.button("‚úÖ Finalizar", key=f"complete_baseline_{project_id}"):
            if baseline_data['ctq_metrics'] and baseline_period.strip():
                _save_tool_data(project_id, 'baseline_data', {
                    'ctq_metrics': baseline_data['ctq_metrics'],
                    'baseline_period': baseline_period,
                    'data_source': data_source
                }, True)
                st.success("‚úÖ Finalizado!")
                st.balloons()
            else:
                st.error("‚ùå Adicione pelo menos uma m√©trica CTQ e o per√≠odo")


def _save_tool_data(project_id: str, tool_name: str, data: dict, completed: bool = False):
    """Fun√ß√£o auxiliar para salvar dados das ferramentas"""
    try:
        project_manager = ProjectManager()
        
        update_data = {
            f'measure.{tool_name}.data': data,
            f'measure.{tool_name}.completed': completed,
            f'measure.{tool_name}.updated_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        success = project_manager.update_project(project_id, update_data)
        
        if success and 'current_project' in st.session_state:
            # Atualizar session_state
            if 'measure' not in st.session_state.current_project:
                st.session_state.current_project['measure'] = {}
            if tool_name not in st.session_state.current_project['measure']:
                st.session_state.current_project['measure'][tool_name] = {}
            
            st.session_state.current_project['measure'][tool_name]['data'] = data
            st.session_state.current_project['measure'][tool_name]['completed'] = completed
            st.session_state.current_project['measure'][tool_name]['updated_at'] = datetime.now().isoformat()
        
        return success
        
    except Exception as e:
        st.error(f"‚ùå Erro ao salvar: {str(e)}")
        return False


def show_measure_tools(project_data: Dict):
    """Fun√ß√£o principal para mostrar as ferramentas da fase Measure - VERS√ÉO INTEGRADA"""
    
    if not project_data:
        st.error("‚ùå Projeto n√£o encontrado")
        return
    
    project_id = project_data.get('id')
    
    # Inicializar gerenciador de sincroniza√ß√£o
    sync_manager = DataSyncManager(project_id)
    
    # Menu de ferramentas
    st.markdown("### üîß Ferramentas da Fase Measure")
    st.markdown("Colete e analise dados para estabelecer o baseline do processo.")
    
    tool_options = {
        "data_collection_plan": ("üìä", "Plano de Coleta de Dados"),
        "file_upload": ("üìÅ", "Upload e An√°lise de Dados"), 
        "process_capability": ("üìê", "Capacidade do Processo"),
        "msa": ("üéØ", "MSA - Sistema de Medi√ß√£o"),
        "baseline_data": ("üìà", "Baseline e M√©tricas CTQ")
    }
    
    # Verificar status das ferramentas
    measure_data = project_data.get('measure', {})
    
    # Criar lista de ferramentas com status
    tool_names_with_status = []
    tool_keys = list(tool_options.keys())
    
    for key, (icon, name) in tool_options.items():
        tool_data = measure_data.get(key, {})
        is_completed = tool_data.get('completed', False) if isinstance(tool_data, dict) else False
        status_icon = "‚úÖ" if is_completed else "‚è≥"
        tool_names_with_status.append(f"{status_icon} {icon} {name}")
    
    # Seletor de ferramenta
    selected_index = st.selectbox(
        "Selecione uma ferramenta para usar:",
        range(len(tool_names_with_status)),
        format_func=lambda x: tool_names_with_status[x],
        key=f"measure_tool_selector_{project_id}",
        help="Escolha a ferramenta que deseja usar na fase Measure"
    )
    
    selected_tool = tool_keys[selected_index]
    
    st.divider()
    
    # Mostrar status de sincroniza√ß√£o na sidebar
    with st.sidebar:
        st.markdown("### üîÑ Status dos Dados")
        
        # Verificar se h√° dados carregados
        has_data = sync_manager.ensure_data_available(show_warnings=False)
        
        if has_data:
            st.success("‚úÖ Dados dispon√≠veis")
            upload_info = sync_manager.project_manager.get_upload_info(project_id)
            if upload_info:
                st.write(f"üìÑ {upload_info.get('filename', 'N/A')}")
                shape = upload_info.get('shape', [0, 0])
                st.write(f"üìä {shape[0]} √ó {shape[1]}")
        else:
            st.warning("‚ö†Ô∏è Sem dados carregados")
            st.info("Use 'Upload e An√°lise de Dados'")
    
    # Mostrar ferramenta selecionada
    if selected_tool == "data_collection_plan":
        show_data_collection_plan(project_data)
    elif selected_tool == "file_upload":
        show_file_upload_analysis(project_data)
    elif selected_tool == "process_capability":
        show_process_capability(project_data)
    elif selected_tool == "msa":
        show_msa_analysis(project_data)
    elif selected_tool == "baseline_data":
        show_baseline_metrics(project_data)
    
    # Progresso geral da fase Measure
    st.divider()
    st.markdown("### üìä Progresso da Fase Measure")
    
    # Recarregar dados atualizados
    if 'current_project' in st.session_state:
        updated_measure_data = st.session_state.current_project.get('measure', {})
    else:
        updated_measure_data = measure_data
    
    total_tools = len(tool_options)
    completed_tools = 0
    
    # Status das ferramentas
    st.markdown("#### üìã Status das Ferramentas")
    
    cols = st.columns(len(tool_options))
    
    for i, (key, (icon, name)) in enumerate(tool_options.items()):
        tool_data = updated_measure_data.get(key, {})
        is_completed = tool_data.get('completed', False) if isinstance(tool_data, dict) else False
        
        if is_completed:
            completed_tools += 1
        
        with cols[i]:
            if is_completed:
                st.success(f"‚úÖ {name}")
            else:
                st.info(f"‚è≥ {name}")
    
    # Barra de progresso
    progress = (completed_tools / total_tools) * 100
    
    col_prog1, col_prog2 = st.columns([3, 1])
    
    with col_prog1:
        st.progress(progress / 100)
        st.caption(f"{completed_tools}/{total_tools} ferramentas conclu√≠das ({progress:.1f}%)")
    
    with col_prog2:
        if progress == 100:
            st.success("üéâ Completo!")
        else:
            st.info(f"‚è≥ {progress:.0f}%")
    
    # Conclus√£o da fase
    if progress == 100:
        st.success("üéâ **Parab√©ns! Fase Measure conclu√≠da com sucesso!**")
        st.info("‚ú® Voc√™ pode avan√ßar para a fase **Analyze** usando a navega√ß√£o das fases.")
        
        # Resumo das principais m√©tricas
        st.markdown("### üìà Resumo das Principais M√©tricas")
        
        metrics_summary = []
        
        # Dados carregados
        upload_info = sync_manager.project_manager.get_upload_info(project_id)
        if upload_info:
            shape = upload_info.get('shape', [0, 0])
            metrics_summary.append(f"üìä **Dados:** {shape[0]} observa√ß√µes, {shape[1]} vari√°veis")
        
        # Baseline
        baseline_data = updated_measure_data.get('baseline_data', {}).get('data', {})
        if baseline_data.get('ctq_metrics'):
            ctq_count = len(baseline_data['ctq_metrics'])
            metrics_summary.append(f"üéØ **CTQs:** {ctq_count} m√©trica(s) cr√≠tica(s) definida(s)")
        
        # Capacidade
        capability_data = updated_measure_data.get('process_capability', {}).get('data', {})
        if capability_data.get('capability_status'):
            status = capability_data['capability_status']
            metrics_summary.append(f"üìê **Capacidade:** Processo {status}")
        
        # MSA
        msa_data = updated_measure_data.get('msa', {}).get('data', {})
        if msa_data.get('interpretation'):
            interpretation = msa_data['interpretation']
            metrics_summary.append(f"üéØ **MSA:** Sistema de medi√ß√£o {interpretation}")
        
        if metrics_summary:
            for metric in metrics_summary:
                st.write(metric)
        else:
            st.info("Complete as ferramentas para ver o resumo das m√©tricas")
    
    # Debug opcional
    with st.expander("üîç Debug - Dados da Fase Measure"):
        st.json(updated_measure_data)
