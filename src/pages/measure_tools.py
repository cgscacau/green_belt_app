import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import io
import base64
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from src.utils.project_manager import ProjectManager
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def show_data_collection_plan(project_data: Dict):
    """Plano de Coleta de Dados"""
    
    project_id = project_data.get('id')
    project_manager = ProjectManager()
    
    st.markdown("## üìä Plano de Coleta de Dados")
    st.markdown("Defina **o que**, **como**, **quando** e **onde** coletar os dados do processo.")
    
    # Inicializar dados no session_state
    plan_key = f"data_plan_{project_id}"
    if plan_key not in st.session_state:
        existing_data = project_data.get('measure', {}).get('data_collection_plan', {}).get('data', {})
        st.session_state[plan_key] = existing_data if existing_data else {}
    
    plan_data = st.session_state[plan_key]
    
    # Status atual
    is_completed = project_data.get('measure', {}).get('data_collection_plan', {}).get('completed', False)
    if is_completed:
        st.success("‚úÖ Plano de coleta finalizado")
    else:
        st.info("‚è≥ Plano em desenvolvimento")
    
    # Se√ß√£o 1: Objetivos da Coleta
    st.markdown("### üéØ Objetivos da Coleta de Dados")
    
    collection_objective = st.text_area(
        "Objetivo Principal da Coleta *",
        value=plan_data.get('collection_objective', ''),
        placeholder="Ex: Medir a variabilidade do tempo de setup das m√°quinas...",
        height=80,
        key=f"collection_objective_{project_id}",
        help="Por que estamos coletando estes dados?"
    )
    
    # Se√ß√£o 2: Vari√°veis a Medir
    st.markdown("### üìè Vari√°veis a Serem Medidas")
    
    # Inicializar lista de vari√°veis
    if 'variables' not in plan_data or plan_data['variables'] is None:
        plan_data['variables'] = []
        st.session_state[plan_key] = plan_data
    
    # Adicionar nova vari√°vel
    with st.expander("‚ûï Adicionar Nova Vari√°vel"):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            var_name = st.text_input("Nome da Vari√°vel *", placeholder="Ex: Tempo de Setup", key=f"var_name_{project_id}")
            var_type = st.selectbox("Tipo de Dados", options=["Cont√≠nua", "Discreta", "Categ√≥rica", "Bin√°ria"], key=f"var_type_{project_id}")
        
        with col2:
            var_unit = st.text_input("Unidade de Medida", placeholder="Ex: minutos, pe√ßas, %", key=f"var_unit_{project_id}")
            var_target = st.text_input("Valor Alvo/Especifica√ß√£o", placeholder="Ex: < 30 min, 0 defeitos", key=f"var_target_{project_id}")
        
        with col3:
            var_importance = st.selectbox("Import√¢ncia", options=["Alta", "M√©dia", "Baixa"], key=f"var_importance_{project_id}")
            var_frequency = st.selectbox("Frequ√™ncia de Coleta", options=["Cont√≠nua", "Hor√°ria", "Di√°ria", "Semanal", "Por Lote"], key=f"var_frequency_{project_id}")
        
        var_description = st.text_area("Descri√ß√£o da Vari√°vel", placeholder="Como esta vari√°vel ser√° medida?", height=60, key=f"var_description_{project_id}")
        
        if st.button("‚ûï Adicionar Vari√°vel", key=f"add_variable_{project_id}"):
            if var_name.strip():
                new_variable = {
                    'id': len(plan_data['variables']) + 1,
                    'name': var_name.strip(),
                    'type': var_type,
                    'unit': var_unit,
                    'target': var_target,
                    'importance': var_importance,
                    'frequency': var_frequency,
                    'description': var_description,
                    'created_at': datetime.now().isoformat()
                }
                
                plan_data['variables'].append(new_variable)
                st.session_state[plan_key] = plan_data
                st.success(f"‚úÖ Vari√°vel '{var_name}' adicionada!")
                st.rerun()
            else:
                st.error("‚ùå Nome da vari√°vel √© obrigat√≥rio")
    
    # Mostrar vari√°veis cadastradas
    if plan_data['variables'] and len(plan_data['variables']) > 0:
        st.markdown("#### üìã Vari√°veis Cadastradas")
        
        for i, var in enumerate(plan_data['variables']):
            with st.expander(f"{var['name']} ({var['type']}) - Import√¢ncia: {var['importance']}"):
                col1, col2, col3 = st.columns([2, 2, 1])
                
                with col1:
                    st.write(f"**Unidade:** {var.get('unit', 'N/A')}")
                    st.write(f"**Frequ√™ncia:** {var['frequency']}")
                
                with col2:
                    st.write(f"**Alvo:** {var.get('target', 'N/A')}")
                    st.write(f"**Descri√ß√£o:** {var.get('description', 'N/A')}")
                
                with col3:
                    if st.button("üóëÔ∏è Remover", key=f"remove_var_{i}_{project_id}"):
                        plan_data['variables'].pop(i)
                        st.session_state[plan_key] = plan_data
                        st.rerun()
    
    # Se√ß√£o 3: M√©todo de Coleta
    st.markdown("### üîß M√©todo de Coleta")
    
    col1, col2 = st.columns(2)
    
    with col1:
        collection_method_options = ["Medi√ß√£o Direta", "Observa√ß√£o", "Sistema Automatizado", "Formul√°rio/Checklist", "Sensor/Equipamento", "Amostragem"]
        current_method = plan_data.get('collection_method', 'Medi√ß√£o Direta')
        try:
            method_index = collection_method_options.index(current_method)
        except ValueError:
            method_index = 0
            
        collection_method = st.selectbox(
            "M√©todo Principal *",
            options=collection_method_options,
            index=method_index,
            key=f"collection_method_{project_id}"
        )
        
        data_source = st.text_input(
            "Fonte dos Dados *",
            value=plan_data.get('data_source', ''),
            placeholder="Ex: Sistema ERP, Relat√≥rios de produ√ß√£o...",
            key=f"data_source_{project_id}"
        )
    
    with col2:
        responsible_person = st.text_input(
            "Respons√°vel pela Coleta *",
            value=plan_data.get('responsible_person', ''),
            placeholder="Nome do respons√°vel",
            key=f"responsible_person_{project_id}"
        )
        
        collection_location = st.text_input(
            "Local da Coleta",
            value=plan_data.get('collection_location', ''),
            placeholder="Ex: Linha de produ√ß√£o 1, Setor de qualidade...",
            key=f"collection_location_{project_id}"
        )
    
    # Se√ß√£o 4: Cronograma
    st.markdown("### üìÖ Cronograma da Coleta")
    
    col3, col4, col5 = st.columns(3)
    
    with col3:
        try:
            start_date_value = datetime.fromisoformat(plan_data.get('start_date', datetime.now().isoformat())).date()
        except:
            start_date_value = datetime.now().date()
            
        start_date = st.date_input(
            "Data de In√≠cio *",
            value=start_date_value,
            key=f"start_date_{project_id}"
        )
    
    with col4:
        try:
            end_date_value = datetime.fromisoformat(plan_data.get('end_date', (datetime.now() + timedelta(days=30)).isoformat())).date()
        except:
            end_date_value = (datetime.now() + timedelta(days=30)).date()
            
        end_date = st.date_input(
            "Data de Fim *",
            value=end_date_value,
            key=f"end_date_{project_id}"
        )
    
    with col5:
        sample_size = st.number_input(
            "Tamanho da Amostra",
            value=int(plan_data.get('sample_size', 30)),
            min_value=1,
            step=1,
            key=f"sample_size_{project_id}",
            help="Quantidade m√≠nima de dados a coletar"
        )
    
    # Se√ß√£o 5: Considera√ß√µes Especiais
    st.markdown("### ‚ö†Ô∏è Considera√ß√µes Especiais")
    
    col6, col7 = st.columns(2)
    
    with col6:
        potential_issues = st.text_area(
            "Problemas Potenciais",
            value=plan_data.get('potential_issues', ''),
            placeholder="Que problemas podem ocorrer na coleta?",
            height=80,
            key=f"potential_issues_{project_id}"
        )
    
    with col7:
        mitigation_actions = st.text_area(
            "A√ß√µes de Mitiga√ß√£o",
            value=plan_data.get('mitigation_actions', ''),
            placeholder="Como prevenir/resolver os problemas?",
            height=80,
            key=f"mitigation_actions_{project_id}"
        )
    
    # Bot√µes de a√ß√£o
    st.divider()
    
    col8, col9, col10 = st.columns([2, 1, 1])
    
    with col9:
        save_plan = st.button("üíæ Salvar Plano", use_container_width=True, key=f"save_plan_{project_id}")
    
    with col10:
        finalize_plan = st.button("‚úÖ Finalizar Plano", use_container_width=True, type="primary", key=f"finalize_plan_{project_id}")
    
    # Processar a√ß√µes
    if save_plan or finalize_plan:
        # Coletar dados atuais
        current_data = {
            'collection_objective': st.session_state.get(f"collection_objective_{project_id}", ''),
            'variables': plan_data.get('variables', []),
            'collection_method': st.session_state.get(f"collection_method_{project_id}", ''),
            'data_source': st.session_state.get(f"data_source_{project_id}", ''),
            'responsible_person': st.session_state.get(f"responsible_person_{project_id}", ''),
            'collection_location': st.session_state.get(f"collection_location_{project_id}", ''),
            'start_date': st.session_state.get(f"start_date_{project_id}", datetime.now().date()).isoformat(),
            'end_date': st.session_state.get(f"end_date_{project_id}", datetime.now().date()).isoformat(),
            'sample_size': st.session_state.get(f"sample_size_{project_id}", 30),
            'potential_issues': st.session_state.get(f"potential_issues_{project_id}", ''),
            'mitigation_actions': st.session_state.get(f"mitigation_actions_{project_id}", ''),
            'last_saved': datetime.now().isoformat()
        }
        
        # Validar campos obrigat√≥rios se finalizando
        if finalize_plan:
            required_fields = [
                (current_data['collection_objective'], "Objetivo da Coleta"),
                (current_data['data_source'], "Fonte dos Dados"),
                (current_data['responsible_person'], "Respons√°vel pela Coleta")
            ]
            
            missing_fields = [field_name for field_value, field_name in required_fields if not str(field_value).strip()]
            
            if missing_fields:
                st.error(f"‚ùå Campos obrigat√≥rios: {', '.join(missing_fields)}")
                st.stop()
            
            if not current_data['variables'] or len(current_data['variables']) == 0:
                st.error("‚ùå Adicione pelo menos uma vari√°vel para medir")
                st.stop()
        
        # Salvar
        st.session_state[plan_key] = current_data
        
        # Salvar no Firebase
        update_data = {
            f'measure.data_collection_plan.data': current_data,
            f'measure.data_collection_plan.completed': finalize_plan,
            f'measure.data_collection_plan.updated_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        with st.spinner("üíæ Salvando..."):
            try:
                success = project_manager.update_project(project_id, update_data)
                
                if success:
                    # Atualizar session_state do projeto
                    if 'current_project' in st.session_state:
                        if 'measure' not in st.session_state.current_project:
                            st.session_state.current_project['measure'] = {}
                        if 'data_collection_plan' not in st.session_state.current_project['measure']:
                            st.session_state.current_project['measure']['data_collection_plan'] = {}
                        
                        st.session_state.current_project['measure']['data_collection_plan']['data'] = current_data
                        st.session_state.current_project['measure']['data_collection_plan']['completed'] = finalize_plan
                    
                    if finalize_plan:
                        st.success("‚úÖ Plano de coleta finalizado e salvo!")
                        st.balloons()
                        
                        # Mostrar resumo
                        st.markdown("### üìä Resumo do Plano")
                        col_sum1, col_sum2, col_sum3 = st.columns(3)
                        
                        with col_sum1:
                            st.metric("Vari√°veis a Medir", len(current_data['variables']))
                        
                        with col_sum2:
                            try:
                                duration = (datetime.fromisoformat(current_data['end_date']) - datetime.fromisoformat(current_data['start_date'])).days
                                st.metric("Dura√ß√£o", f"{duration} dias")
                            except:
                                st.metric("Dura√ß√£o", "N/A")
                        
                        with col_sum3:
                            st.metric("Tamanho da Amostra", current_data['sample_size'])
                        
                    else:
                        st.success("üíæ Plano salvo com sucesso!")
                
                else:
                    st.error("‚ùå Erro ao salvar no Firebase")
                    
            except Exception as e:
                st.error(f"‚ùå Erro ao salvar: {str(e)}")


def show_file_upload_analysis(project_data: Dict):
    """Upload e An√°lise de Arquivos - VERS√ÉO CORRIGIDA"""
    
    project_id = project_data.get('id')
    
    st.markdown("## üìÅ Upload e An√°lise de Dados")
    st.markdown("Fa√ßa upload dos seus dados e realize an√°lises estat√≠sticas b√°sicas.")
    
    # Upload de arquivo
    st.markdown("### üì§ Upload de Arquivo")
    
    uploaded_file = st.file_uploader(
        "Escolha um arquivo",
        type=['csv', 'xlsx', 'xls', 'txt'],
        help="Formatos suportados: CSV, Excel (.xlsx, .xls), TXT",
        key=f"file_upload_{project_id}"
    )
    
    if uploaded_file is not None:
        try:
            # Ler arquivo baseado na extens√£o
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            if file_extension == 'csv':
                # Tentar diferentes separadores
                try:
                    df = pd.read_csv(uploaded_file, sep=',')
                except:
                    uploaded_file.seek(0)
                    try:
                        df = pd.read_csv(uploaded_file, sep=';')
                    except:
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, sep='\t')
            
            elif file_extension in ['xlsx', 'xls']:
                df = pd.read_excel(uploaded_file)
            
            elif file_extension == 'txt':
                try:
                    df = pd.read_csv(uploaded_file, sep='\t')
                except:
                    uploaded_file.seek(0)
                    try:
                        df = pd.read_csv(uploaded_file, sep=',')
                    except:
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, sep=';')
            
            # CORRE√á√ÉO: Processamento mais robusto dos dados
            st.info("üîÑ Processando dados...")
            
            # Limpeza inicial dos dados
            for col in df.columns:
                if df[col].dtype == 'object':
                    # Converter para string e limpar
                    df[col] = df[col].astype(str)
                    df[col] = df[col].str.strip()
                    
                    # Substituir valores vazios por NaN
                    df[col] = df[col].replace(['', 'nan', 'NaN', 'null', 'NULL'], np.nan)
            
            # Tentar convers√£o inteligente para num√©rico
            original_numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            converted_cols = []
            
            for col in df.columns:
                if col not in original_numeric_cols:
                    # Tentar convers√£o para num√©rico
                    try:
                        # Fazer uma c√≥pia da coluna para teste
                        test_col = df[col].copy()
                        
                        # Se for object, tentar limpar e converter
                        if test_col.dtype == 'object':
                            # Remover caracteres n√£o num√©ricos (exceto . , - +)
                            test_col = test_col.astype(str)
                            
                            # Substituir v√≠rgula por ponto
                            test_col = test_col.str.replace(',', '.')
                            
                            # Remover espa√ßos
                            test_col = test_col.str.strip()
                            
                            # Tentar converter para float
                            test_converted = pd.to_numeric(test_col, errors='coerce')
                            
                            # Se conseguiu converter pelo menos 50% dos dados n√£o-nulos
                            non_null_original = test_col.notna().sum()
                            non_null_converted = test_converted.notna().sum()
                            
                            if non_null_original > 0 and (non_null_converted / non_null_original) >= 0.5:
                                df[col] = test_converted
                                converted_cols.append(col)
                                
                    except Exception as e:
                        # Se der erro, manter como estava
                        continue
            
            # Salvar dados no session_state
            st.session_state[f'uploaded_data_{project_id}'] = df
            st.session_state[f'file_name_{project_id}'] = uploaded_file.name
            
            st.success(f"‚úÖ Arquivo '{uploaded_file.name}' carregado com sucesso!")
            
            if converted_cols:
                st.info(f"üîÑ Colunas convertidas para num√©rico: {', '.join(converted_cols)}")
            
            # Informa√ß√µes b√°sicas do arquivo
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Linhas", df.shape[0])
            
            with col2:
                st.metric("Colunas", df.shape[1])
            
            with col3:
                numeric_cols = len(df.select_dtypes(include=[np.number]).columns)
                st.metric("Colunas Num√©ricas", numeric_cols)
            
            with col4:
                missing_values = df.isnull().sum().sum()
                st.metric("Valores Faltantes", missing_values)
            
        except Exception as e:
            st.error(f"‚ùå Erro ao ler arquivo: {str(e)}")
            st.info("üí° Verifique se o arquivo est√° no formato correto e n√£o est√° corrompido.")
    
    # An√°lise dos dados carregados
    if f'uploaded_data_{project_id}' in st.session_state:
        df = st.session_state[f'uploaded_data_{project_id}']
        file_name = st.session_state.get(f'file_name_{project_id}', 'arquivo.csv')
        
        st.markdown("### üìä An√°lise dos Dados")
        
        # DEBUG: Mostrar tipos de dados
        debug_mode = st.checkbox("üîç Debug - Mostrar tipos de dados", key=f"debug_types_{project_id}")
        if debug_mode:
            st.write("**Tipos de dados por coluna:**")
            debug_info = []
            for col in df.columns:
                non_null_count = df[col].notna().sum()
                debug_info.append({
                    'Coluna': col,
                    'Tipo': str(df[col].dtype),
                    'Valores N√£o-Nulos': non_null_count,
                    'Amostra': str(df[col].dropna().iloc[0]) if non_null_count > 0 else 'N/A'
                })
            st.dataframe(pd.DataFrame(debug_info), use_container_width=True)
        
        # Tabs para diferentes an√°lises
        tab1, tab2, tab3, tab4 = st.tabs(["üëÄ Visualizar", "üìà Estat√≠sticas", "üìä Gr√°ficos", "üîç Qualidade"])
        
        with tab1:
            st.markdown("#### üìã Preview dos Dados")
            
            col1, col2 = st.columns(2)
            
            with col1:
                show_rows = st.slider("Linhas a mostrar", 5, min(100, len(df)), 10, key=f"show_rows_{project_id}")
            
            with col2:
                show_info = st.checkbox("Mostrar informa√ß√µes das colunas", key=f"show_info_{project_id}")
            
            # Mostrar dados
            st.dataframe(df.head(show_rows), use_container_width=True)
            
            if show_info:
                st.markdown("#### ‚ÑπÔ∏è Informa√ß√µes das Colunas")
                
                info_data = []
                for col in df.columns:
                    info_data.append({
                        'Coluna': col,
                        'Tipo': str(df[col].dtype),
                        'Valores √önicos': df[col].nunique(),
                        'Valores Nulos': df[col].isnull().sum(),
                        'Exemplo': str(df[col].dropna().iloc[0]) if not df[col].dropna().empty else 'N/A'
                    })
                
                st.dataframe(pd.DataFrame(info_data), use_container_width=True)
        
        with tab2:
            st.markdown("#### üìä Estat√≠sticas Descritivas")
            
            # Detectar colunas num√©ricas
            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
            
            if numeric_columns:
                st.success(f"‚úÖ Encontradas {len(numeric_columns)} colunas num√©ricas: {', '.join(numeric_columns)}")
                
                # Filtrar colunas que t√™m dados v√°lidos
                valid_numeric_columns = []
                for col in numeric_columns:
                    valid_data_count = df[col].dropna().shape[0]
                    if valid_data_count > 0:
                        valid_numeric_columns.append(col)
                
                if not valid_numeric_columns:
                    st.error("‚ùå As colunas num√©ricas n√£o possuem dados v√°lidos")
                    return
                
                selected_columns = st.multiselect(
                    "Selecione as colunas para an√°lise:",
                    valid_numeric_columns,
                    default=valid_numeric_columns[:5] if len(valid_numeric_columns) >= 5 else valid_numeric_columns,
                    key=f"selected_cols_{project_id}"
                )
                
                if selected_columns:
                    try:
                        # CORRE√á√ÉO: Filtrar apenas dados v√°lidos para estat√≠sticas
                        df_clean = df[selected_columns].copy()
                        
                        # Remover linhas onde todas as colunas selecionadas s√£o NaN
                        df_clean = df_clean.dropna(how='all')
                        
                        if df_clean.empty:
                            st.error("‚ùå N√£o h√° dados v√°lidos nas colunas selecionadas")
                            return
                        
                        st.info(f"üìä Calculando estat√≠sticas para {len(df_clean)} linhas v√°lidas")
                        
                        # Estat√≠sticas descritivas b√°sicas
                        stats_df = df_clean.describe()
                        st.dataframe(stats_df.round(4), use_container_width=True)
                        
                        # Estat√≠sticas adicionais
                        st.markdown("#### üìà Estat√≠sticas Adicionais")
                        
                        additional_stats = []
                        for col in selected_columns:
                            data_col = df_clean[col].dropna()
                            
                            if len(data_col) > 0:
                                try:
                                    # Calcular moda de forma segura
                                    mode_values = data_col.mode()
                                    mode_val = mode_values.iloc[0] if len(mode_values) > 0 else np.nan
                                    
                                    # Calcular coeficiente de varia√ß√£o
                                    mean_val = data_col.mean()
                                    std_val = data_col.std()
                                    cv = (std_val / mean_val * 100) if mean_val != 0 and not np.isnan(mean_val) else 0
                                    
                                    # Calcular assimetria e curtose
                                    skewness = stats.skew(data_col) if len(data_col) > 2 else 0
                                    kurt = stats.kurtosis(data_col) if len(data_col) > 2 else 0
                                    
                                    additional_stats.append({
                                        'Coluna': col,
                                        'Mediana': f"{data_col.median():.4f}",
                                        'Moda': f"{mode_val:.4f}" if not np.isnan(mode_val) else 'N/A',
                                        'Vari√¢ncia': f"{data_col.var():.4f}",
                                        'Coef. Varia√ß√£o': f"{cv:.2f}%",
                                        'Assimetria': f"{skewness:.4f}",
                                        'Curtose': f"{kurt:.4f}",
                                        'Dados V√°lidos': len(data_col)
                                    })
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Erro ao calcular estat√≠sticas para {col}: {str(e)}")
                        
                        if additional_stats:
                            st.dataframe(pd.DataFrame(additional_stats), use_container_width=True)
                        else:
                            st.error("‚ùå N√£o foi poss√≠vel calcular estat√≠sticas adicionais")
                            
                    except Exception as e:
                        st.error(f"‚ùå Erro ao calcular estat√≠sticas: {str(e)}")
                        
                        # Tentar diagn√≥stico do problema
                        st.markdown("**üîç Diagn√≥stico:**")
                        for col in selected_columns:
                            col_info = df[col].describe() if pd.api.types.is_numeric_dtype(df[col]) else "N√£o num√©rica"
                            st.write(f"- {col}: {col_info}")
                        
                else:
                    st.info("üëÜ Selecione pelo menos uma coluna para an√°lise")
                    
            else:
                st.warning("‚ö†Ô∏è Nenhuma coluna num√©rica encontrada")
                
                # Oferecer convers√£o manual
                st.markdown("**üîß Convers√£o Manual de Colunas**")
                
                all_columns = df.columns.tolist()
                cols_to_convert = st.multiselect(
                    "Selecione colunas para tentar converter para num√©rico:",
                    all_columns,
                    key=f"manual_convert_{project_id}"
                )
                
                if st.button("üîÑ Tentar Convers√£o", key=f"try_convert_{project_id}") and cols_to_convert:
                    df_converted = df.copy()
                    conversion_results = []
                    
                    for col in cols_to_convert:
                        try:
                            original_data = df_converted[col].copy()
                            
                            # Tentar diferentes m√©todos de convers√£o
                            if original_data.dtype == 'object':
                                # M√©todo 1: Convers√£o direta
                                try:
                                    converted = pd.to_numeric(original_data, errors='coerce')
                                    success_rate = converted.notna().sum() / original_data.notna().sum()
                                    
                                    if success_rate > 0.1:  # Se pelo menos 10% converteu
                                        df_converted[col] = converted
                                        conversion_results.append(f"‚úÖ {col}: {success_rate:.1%} convertido")
                                        continue
                                except:
                                    pass
                                
                                # M√©todo 2: Limpeza e convers√£o
                                try:
                                    cleaned = original_data.astype(str).str.strip()
                                    cleaned = cleaned.str.replace(',', '.')
                                    cleaned = cleaned.str.replace(r'[^\d.-]', '', regex=True)
                                    converted = pd.to_numeric(cleaned, errors='coerce')
                                    success_rate = converted.notna().sum() / original_data.notna().sum()
                                    
                                    if success_rate > 0.1:
                                        df_converted[col] = converted
                                        conversion_results.append(f"‚úÖ {col}: {success_rate:.1%} convertido (com limpeza)")
                                        continue
                                except:
                                    pass
                            
                            conversion_results.append(f"‚ùå {col}: N√£o foi poss√≠vel converter")
                            
                        except Exception as e:
                            conversion_results.append(f"‚ùå {col}: Erro - {str(e)}")
                    
                    # Mostrar resultados
                    for result in conversion_results:
                        if result.startswith("‚úÖ"):
                            st.success(result)
                        else:
                            st.warning(result)
                    
                    # Atualizar DataFrame se houve convers√µes bem-sucedidas
                    new_numeric_cols = df_converted.select_dtypes(include=[np.number]).columns.tolist()
                    if len(new_numeric_cols) > len(numeric_columns):
                        st.session_state[f'uploaded_data_{project_id}'] = df_converted
                        st.success("üîÑ DataFrame atualizado! Recarregue a p√°gina para ver as mudan√ßas.")
                        st.rerun()
        
        with tab3:
            st.markdown("#### üìä Visualiza√ß√µes")
            
            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
            
            if numeric_columns:
                chart_type = st.selectbox(
                    "Tipo de Gr√°fico:",
                    ["Histograma", "Box Plot", "Linha do Tempo", "Scatter Plot", "Correla√ß√£o"],
                    key=f"chart_type_{project_id}"
                )
                
                try:
                    if chart_type == "Histograma":
                        col_to_plot = st.selectbox("Coluna:", numeric_columns, key=f"hist_col_{project_id}")
                        
                        # Filtrar dados v√°lidos
                        valid_data = df[col_to_plot].dropna()
                        if len(valid_data) > 0:
                            fig = px.histogram(x=valid_data, nbins=30, title=f"Histograma - {col_to_plot}")
                            fig.update_layout(height=400)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.warning("‚ö†Ô∏è N√£o h√° dados v√°lidos para plotar")
                    
                    elif chart_type == "Box Plot":
                        cols_to_plot = st.multiselect("Colunas:", numeric_columns, default=numeric_columns[:3], key=f"box_cols_{project_id}")
                        
                        if cols_to_plot:
                            fig = go.Figure()
                            for col in cols_to_plot:
                                valid_data = df[col].dropna()
                                if len(valid_data) > 0:
                                    fig.add_trace(go.Box(y=valid_data, name=col))
                            
                            fig.update_layout(title="Box Plot - Compara√ß√£o", height=400)
                            st.plotly_chart(fig, use_container_width=True)
                    
                    elif chart_type == "Linha do Tempo":
                        y_col = st.selectbox("Eixo Y:", numeric_columns, key=f"line_y_{project_id}")
                        
                        valid_data = df[y_col].dropna()
                        if len(valid_data) > 0:
                            fig = px.line(x=range(len(valid_data)), y=valid_data, title=f"S√©rie Temporal - {y_col}")
                            fig.update_layout(height=400)
                            st.plotly_chart(fig, use_container_width=True)
                        else:
                            st.warning("‚ö†Ô∏è N√£o h√° dados v√°lidos para plotar")
                    
                    elif chart_type == "Scatter Plot":
                        if len(numeric_columns) >= 2:
                            col1, col2 = st.columns(2)
                            with col1:
                                x_col = st.selectbox("Eixo X:", numeric_columns, key=f"scatter_x_{project_id}")
                            with col2:
                                available_y_cols = [col for col in numeric_columns if col != x_col]
                                if available_y_cols:
                                    y_col = st.selectbox("Eixo Y:", available_y_cols, key=f"scatter_y_{project_id}")
                                    
                                    # Filtrar dados v√°lidos para ambas as colunas
                                    df_scatter = df[[x_col, y_col]].dropna()
                                    if len(df_scatter) > 0:
                                        fig = px.scatter(df_scatter, x=x_col, y=y_col, title=f"Scatter Plot - {x_col} vs {y_col}")
                                        fig.update_layout(height=400)
                                        st.plotly_chart(fig, use_container_width=True)
                                    else:
                                        st.warning("‚ö†Ô∏è N√£o h√° dados v√°lidos para plotar")
                        else:
                            st.warning("‚ö†Ô∏è Necess√°rio pelo menos 2 colunas num√©ricas para scatter plot")
                    
                    elif chart_type == "Correla√ß√£o":
                        if len(numeric_columns) >= 2:
                            # Filtrar apenas dados v√°lidos
                            df_corr = df[numeric_columns].dropna()
                            if len(df_corr) > 1:
                                corr_matrix = df_corr.corr()
                                
                                fig = px.imshow(corr_matrix, 
                                              text_auto=True, 
                                              aspect="auto",
                                              title="Matriz de Correla√ß√£o",
                                              color_continuous_scale='RdBu_r')
                                fig.update_layout(height=400)
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                st.warning("‚ö†Ô∏è Dados insuficientes para correla√ß√£o")
                        else:
                            st.warning("‚ö†Ô∏è Necess√°rio pelo menos 2 colunas num√©ricas para correla√ß√£o")
                            
                except Exception as e:
                    st.error(f"‚ùå Erro ao criar gr√°fico: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è Nenhuma coluna num√©rica encontrada para visualiza√ß√£o")
        
        with tab4:
            st.markdown("#### üîç An√°lise de Qualidade dos Dados")
            
            # Valores faltantes
            st.markdown("##### üï≥Ô∏è Valores Faltantes")
            missing_data = df.isnull().sum()
            missing_percent = (missing_data / len(df)) * 100
            
            missing_df = pd.DataFrame({
                'Coluna': missing_data.index,
                'Valores Faltantes': missing_data.values,
                'Percentual (%)': missing_percent.values
            })
            
            missing_df = missing_df[missing_df['Valores Faltantes'] > 0]
            
            if not missing_df.empty:
                st.dataframe(missing_df, use_container_width=True)
                
                try:
                    fig = px.bar(missing_df, x='Coluna', y='Percentual (%)', 
                               title="Percentual de Valores Faltantes por Coluna")
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erro ao criar gr√°fico: {str(e)}")
            else:
                st.success("‚úÖ Nenhum valor faltante encontrado!")
            
            # Outliers
            numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_columns:
                st.markdown("##### üéØ Detec√ß√£o de Outliers (M√©todo IQR)")
                
                outlier_col = st.selectbox("Selecione coluna para an√°lise de outliers:", numeric_columns, key=f"outlier_col_{project_id}")
                
                try:
                    data_col = df[outlier_col].dropna()
                    
                    if len(data_col) > 0:
                        Q1 = data_col.quantile(0.25)
                        Q3 = data_col.quantile(0.75)
                        IQR = Q3 - Q1
                        
                        lower_bound = Q1 - 1.5 * IQR
                        upper_bound = Q3 + 1.5 * IQR
                        
                        outliers = data_col[(data_col < lower_bound) | (data_col > upper_bound)]
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Total de Outliers", len(outliers))
                        
                        with col2:
                            st.metric("Limite Inferior", f"{lower_bound:.2f}")
                        
                        with col3:
                            st.metric("Limite Superior", f"{upper_bound:.2f}")
                        
                        if len(outliers) > 0:
                            st.warning(f"‚ö†Ô∏è {len(outliers)} outliers detectados")
                            
                            try:
                                fig = go.Figure()
                                fig.add_trace(go.Box(y=data_col, name=outlier_col, boxpoints='outliers'))
                                fig.update_layout(title=f"Box Plot - {outlier_col}", height=300)
                                st.plotly_chart(fig, use_container_width=True)
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Erro ao criar box plot: {str(e)}")
                        else:
                            st.success("‚úÖ Nenhum outlier detectado!")
                    else:
                        st.warning("‚ö†Ô∏è Coluna n√£o possui dados v√°lidos")
                        
                except Exception as e:
                    st.error(f"‚ùå Erro na an√°lise de outliers: {str(e)}")
        
        # Bot√£o para salvar an√°lise
        st.divider()
        
        if st.button("üíæ Salvar An√°lise de Dados", key=f"save_analysis_{project_id}", use_container_width=True):
            try:
                numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
                
                analysis_summary = {
                    'file_name': file_name,
                    'upload_date': datetime.now().isoformat(),
                    'rows': int(df.shape[0]),
                    'columns': int(df.shape[1]),
                    'numeric_columns': len(numeric_columns),
                    'missing_values': int(df.isnull().sum().sum()),
                    'column_info': [
                        {
                            'name': col,
                            'type': str(df[col].dtype),
                            'unique_values': int(df[col].nunique()),
                            'null_values': int(df[col].isnull().sum())
                        }
                        for col in df.columns
                    ]
                }
                
                update_data = {
                    f'measure.baseline_data.data': analysis_summary,
                    f'measure.baseline_data.completed': True,
                    f'measure.baseline_data.updated_at': datetime.now().isoformat(),
                    'updated_at': datetime.now().isoformat()
                }
                
                project_manager = ProjectManager()
                
                with st.spinner("üíæ Salvando an√°lise..."):
                    success = project_manager.update_project(project_id, update_data)
                    
                    if success:
                        st.success("‚úÖ An√°lise de dados salva com sucesso!")
                        st.balloons()
                    else:
                        st.error("‚ùå Erro ao salvar an√°lise")
                        
            except Exception as e:
                st.error(f"‚ùå Erro ao salvar: {str(e)}")



def show_process_capability(project_data: Dict):
    """An√°lise de Capacidade do Processo"""
    
    project_id = project_data.get('id')
    
    st.markdown("## üìê An√°lise de Capacidade do Processo")
    st.markdown("Avalie se o processo √© capaz de atender √†s especifica√ß√µes.")
    
    # Verificar se h√° dados carregados
    if f'uploaded_data_{project_id}' not in st.session_state:
        st.warning("‚ö†Ô∏è Primeiro fa√ßa upload dos dados na se√ß√£o 'Upload e An√°lise de Dados'")
        return
    
    df = st.session_state[f'uploaded_data_{project_id}']
    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_columns:
        st.error("‚ùå Nenhuma coluna num√©rica encontrada nos dados")
        return
    
    # Sele√ß√£o da vari√°vel para an√°lise
    st.markdown("### üéØ Configura√ß√£o da An√°lise")
    
    col1, col2 = st.columns(2)
    
    with col1:
        selected_column = st.selectbox(
            "Selecione a vari√°vel para an√°lise:",
            numeric_columns,
            key=f"capability_column_{project_id}"
        )
    
    with col2:
        analysis_type = st.selectbox(
            "Tipo de Especifica√ß√£o:",
            ["Bilateral (LSL e USL)", "Unilateral Superior (USL)", "Unilateral Inferior (LSL)"],
            key=f"spec_type_{project_id}"
        )
    
    # Configurar limites de especifica√ß√£o
    st.markdown("### üìè Limites de Especifica√ß√£o")
    
    try:
        data_col = df[selected_column].dropna()
        
        if len(data_col) == 0:
            st.error("‚ùå A coluna selecionada n√£o possui dados v√°lidos")
            return
            
        data_min, data_max = data_col.min(), data_col.max()
        data_mean = data_col.mean()
        data_std = data_col.std()
        
        col3, col4, col5 = st.columns(3)
        
        with col3:
            if analysis_type in ["Bilateral (LSL e USL)", "Unilateral Inferior (LSL)"]:
                lsl = st.number_input(
                    "LSL (Limite Inferior de Especifica√ß√£o)",
                    value=float(data_min - data_std),
                    key=f"lsl_{project_id}",
                    help="Valor m√≠nimo aceit√°vel"
                )
            else:
                lsl = None
        
        with col4:
            if analysis_type in ["Bilateral (LSL e USL)", "Unilateral Superior (USL)"]:
                usl = st.number_input(
                    "USL (Limite Superior de Especifica√ß√£o)",
                    value=float(data_max + data_std),
                    key=f"usl_{project_id}",
                    help="Valor m√°ximo aceit√°vel"
                )
            else:
                usl = None
        
        with col5:
            target = st.number_input(
                "Valor Alvo (Target)",
                value=float(data_mean),
                key=f"target_{project_id}",
                help="Valor ideal do processo"
            )
        
        # Realizar an√°lise de capacidade
        if st.button("üîç Realizar An√°lise de Capacidade", key=f"run_capability_{project_id}"):
            
            # Calcular √≠ndices de capacidade
            results = calculate_capability_indices(data_col, lsl, usl, target)
            
            # Mostrar resultados
            st.markdown("### üìä Resultados da An√°lise")
            
            # M√©tricas principais
            col6, col7, col8, col9 = st.columns(4)
            
            with col6:
                cp_value = results['Cp']
                st.metric("Cp", f"{cp_value:.3f}" if cp_value is not None else "N/A")
            
            with col7:
                cpk_value = results['Cpk']
                st.metric("Cpk", f"{cpk_value:.3f}" if cpk_value is not None else "N/A")
            
            with col8:
                pp_value = results['Pp']
                st.metric("Pp", f"{pp_value:.3f}" if pp_value is not None else "N/A")
            
            with col9:
                ppk_value = results['Ppk']
                st.metric("Ppk", f"{ppk_value:.3f}" if ppk_value is not None else "N/A")
            
            # Interpreta√ß√£o
            st.markdown("### üéØ Interpreta√ß√£o dos Resultados")
            
            interpretation = "N/A"
            if cpk_value is not None:
                if cpk_value >= 1.33:
                    st.success("‚úÖ **Processo Capaz** - Cpk ‚â• 1.33")
                    interpretation = "Excelente"
                elif cpk_value >= 1.0:
                    st.warning("‚ö†Ô∏è **Processo Marginalmente Capaz** - 1.0 ‚â§ Cpk < 1.33")
                    interpretation = "Aceit√°vel"
                else:
                    st.error("‚ùå **Processo N√£o Capaz** - Cpk < 1.0")
                    interpretation = "Inadequado"
            
            # Gr√°fico de capacidade
            st.markdown("### üìà Gr√°fico de Capacidade")
            
            try:
                fig = create_capability_chart(data_col, lsl, usl, target, results)
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"‚ùå Erro ao criar gr√°fico: {str(e)}")
            
            # Estat√≠sticas detalhadas
            st.markdown("### üìã Estat√≠sticas Detalhadas")
            
            detailed_stats = pd.DataFrame({
                'Estat√≠stica': ['M√©dia', 'Desvio Padr√£o', 'M√≠nimo', 'M√°ximo', 'Mediana', 'Q1', 'Q3'],
                'Valor': [
                    f"{data_mean:.4f}",
                    f"{data_std:.4f}",
                    f"{data_min:.4f}",
                    f"{data_max:.4f}",
                    f"{data_col.median():.4f}",
                    f"{data_col.quantile(0.25):.4f}",
                    f"{data_col.quantile(0.75):.4f}"
                ]
            })
            
            col10, col11 = st.columns(2)
            
            with col10:
                st.dataframe(detailed_stats, use_container_width=True)
            
            with col11:
                # Percentual dentro das especifica√ß√µes
                within_spec_pct = None
                
                if lsl is not None and usl is not None:
                    within_spec = ((data_col >= lsl) & (data_col <= usl)).sum()
                    within_spec_pct = (within_spec / len(data_col)) * 100
                    
                    st.metric("Dentro das Especifica√ß√µes", f"{within_spec_pct:.1f}%")
                    st.metric("Fora das Especifica√ß√µes", f"{100 - within_spec_pct:.1f}%")
                
                elif lsl is not None:
                    above_lsl = (data_col >= lsl).sum()
                    above_lsl_pct = (above_lsl / len(data_col)) * 100
                    st.metric("Acima do LSL", f"{above_lsl_pct:.1f}%")
                
                elif usl is not None:
                    below_usl = (data_col <= usl).sum()
                    below_usl_pct = (below_usl / len(data_col)) * 100
                    st.metric("Abaixo do USL", f"{below_usl_pct:.1f}%")
            
            # Salvar resultados
            capability_results = {
                'variable': selected_column,
                'analysis_type': analysis_type,
                'lsl': float(lsl) if lsl is not None else None,
                'usl': float(usl) if usl is not None else None,
                'target': float(target),
                'sample_size': len(data_col),
                'mean': float(data_mean),
                'std': float(data_std),
                'cp': float(cp_value) if cp_value is not None else None,
                'cpk': float(cpk_value) if cpk_value is not None else None,
                'pp': float(pp_value) if pp_value is not None else None,
                'ppk': float(ppk_value) if ppk_value is not None else None,
                'interpretation': interpretation,
                'within_spec_pct': float(within_spec_pct) if within_spec_pct is not None else None,
                'analysis_date': datetime.now().isoformat()
            }
            
            # Salvar no session_state
            st.session_state[f'capability_results_{project_id}'] = capability_results
            
            if st.button("üíæ Salvar An√°lise de Capacidade", key=f"save_capability_{project_id}"):
                # Salvar no Firebase
                update_data = {
                    f'measure.process_capability.data': capability_results,
                    f'measure.process_capability.completed': True,
                    f'measure.process_capability.updated_at': datetime.now().isoformat(),
                    'updated_at': datetime.now().isoformat()
                }
                
                project_manager = ProjectManager()
                
                with st.spinner("üíæ Salvando..."):
                    try:
                        success = project_manager.update_project(project_id, update_data)
                        
                        if success:
                            st.success("‚úÖ An√°lise de capacidade salva!")
                            st.balloons()
                        else:
                            st.error("‚ùå Erro ao salvar")
                            
                    except Exception as e:
                        st.error(f"‚ùå Erro: {str(e)}")
                        
    except Exception as e:
        st.error(f"‚ùå Erro na an√°lise: {str(e)}")


def calculate_capability_indices(data, lsl=None, usl=None, target=None):
    """Calcula √≠ndices de capacidade do processo"""
    
    try:
        mean = data.mean()
        std = data.std()
        
        results = {
            'Cp': None,
            'Cpk': None, 
            'Pp': None,
            'Ppk': None
        }
        
        # Cp e Pp (capacidade potencial)
        if lsl is not None and usl is not None and std > 0:
            results['Cp'] = (usl - lsl) / (6 * std)
            results['Pp'] = results['Cp']  # Para este caso simplificado
        
        # Cpk e Ppk (capacidade real)
        if std > 0:
            if lsl is not None and usl is not None:
                cpu = (usl - mean) / (3 * std)
                cpl = (mean - lsl) / (3 * std)
                results['Cpk'] = min(cpu, cpl)
                results['Ppk'] = results['Cpk']  # Para este caso simplificado
            
            elif usl is not None:
                results['Cpk'] = (usl - mean) / (3 * std)
                results['Ppk'] = results['Cpk']
            
            elif lsl is not None:
                results['Cpk'] = (mean - lsl) / (3 * std)
                results['Ppk'] = results['Cpk']
        
        return results
        
    except Exception as e:
        st.error(f"‚ùå Erro no c√°lculo dos √≠ndices: {str(e)}")
        return {'Cp': None, 'Cpk': None, 'Pp': None, 'Ppk': None}


def create_capability_chart(data, lsl=None, usl=None, target=None, results=None):
    """Cria gr√°fico de capacidade do processo"""
    
    try:
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('Histograma com Especifica√ß√µes', 'Gr√°fico de Controle Individual'),
            vertical_spacing=0.1
        )
        
        # Histograma
        fig.add_trace(
            go.Histogram(x=data, nbinsx=30, name='Dados', opacity=0.7),
            row=1, col=1
        )
        
        # Linhas de especifica√ß√£o
        if lsl is not None:
            fig.add_vline(x=lsl, line_dash="dash", line_color="red", 
                         annotation_text="LSL", row=1, col=1)
        
        if usl is not None:
            fig.add_vline(x=usl, line_dash="dash", line_color="red", 
                         annotation_text="USL", row=1, col=1)
        
        if target is not None:
            fig.add_vline(x=target, line_dash="dot", line_color="green", 
                         annotation_text="Target", row=1, col=1)
        
        # Gr√°fico de controle individual
        fig.add_trace(
            go.Scatter(x=list(range(len(data))), y=data, mode='lines+markers', 
                      name='Valores Individuais', line=dict(color='blue')),
            row=2, col=1
        )
        
        # Linha da m√©dia
        mean_line = data.mean()
        fig.add_hline(y=mean_line, line_dash="solid", line_color="green", 
                     annotation_text="M√©dia", row=2, col=1)
        
        # Limites de controle (¬±3œÉ)
        if data.std() > 0:
            ucl = mean_line + 3 * data.std()
            lcl = mean_line - 3 * data.std()
            
            fig.add_hline(y=ucl, line_dash="dash", line_color="orange", 
                         annotation_text="UCL", row=2, col=1)
            fig.add_hline(y=lcl, line_dash="dash", line_color="orange", 
                         annotation_text="LCL", row=2, col=1)
        
        fig.update_layout(height=600, title_text="An√°lise de Capacidade do Processo")
        
        return fig
        
    except Exception as e:
        st.error(f"‚ùå Erro ao criar gr√°fico: {str(e)}")
        return go.Figure()


def show_msa_analysis(project_data: Dict):
    """An√°lise do Sistema de Medi√ß√£o (MSA) - Vers√£o Simplificada"""
    
    project_id = project_data.get('id')
    
    st.markdown("## üéØ An√°lise do Sistema de Medi√ß√£o (MSA)")
    st.markdown("Avalie a repetibilidade e reprodutibilidade do sistema de medi√ß√£o.")
    
    # Explica√ß√£o do MSA
    with st.expander("‚ÑπÔ∏è O que √© MSA?"):
        st.markdown("""
        **Measurement System Analysis (MSA)** √© uma metodologia estat√≠stica para avaliar a qualidade do sistema de medi√ß√£o.
        
        **Principais componentes:**
        - **Repetibilidade**: Varia√ß√£o quando o mesmo operador mede a mesma pe√ßa v√°rias vezes
        - **Reprodutibilidade**: Varia√ß√£o entre diferentes operadores medindo a mesma pe√ßa
        - **R&R**: Repetibilidade e Reprodutibilidade combinadas
        
        **Crit√©rios de aceita√ß√£o:**
        - R&R < 10%: Sistema excelente
        - 10% ‚â§ R&R < 30%: Sistema aceit√°vel
        - R&R ‚â• 30%: Sistema inadequado
        """)
    
    # Configura√ß√£o do estudo
    st.markdown("### ‚öôÔ∏è Configura√ß√£o do Estudo MSA")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        num_operators = st.number_input(
            "N√∫mero de Operadores",
            min_value=2,
            max_value=5,
            value=3,
            key=f"num_operators_{project_id}",
            help="Recomendado: 2-3 operadores"
        )
    
    with col2:
        num_parts = st.number_input(
            "N√∫mero de Pe√ßas",
            min_value=5,
            max_value=20,
            value=10,
            key=f"num_parts_{project_id}",
            help="Recomendado: 10 pe√ßas"
        )
    
    with col3:
        num_trials = st.number_input(
            "N√∫mero de Repeti√ß√µes",
            min_value=2,
            max_value=5,
            value=3,
            key=f"num_trials_{project_id}",
            help="Recomendado: 2-3 repeti√ß√µes"
        )
    
    # Template para coleta de dados
    st.markdown("### üìã Template para Coleta de Dados")
    
    if st.button("üì• Gerar Template MSA", key=f"generate_template_{project_id}"):
        # Criar template
        template_data = []
        
        for operator in range(1, num_operators + 1):
            for part in range(1, num_parts + 1):
                for trial in range(1, num_trials + 1):
                    template_data.append({
                        'Operador': f'Operador_{operator}',
                        'Pe√ßa': f'Pe√ßa_{part}',
                        'Repeti√ß√£o': trial,
                        'Medi√ß√£o': ''  # Campo vazio para preenchimento
                    })
        
        template_df = pd.DataFrame(template_data)
        
        # Mostrar template
        st.dataframe(template_df.head(20), use_container_width=True)
        
        # Download do template
        csv_template = template_df.to_csv(index=False)
        st.download_button(
            label="üì• Download Template CSV",
            data=csv_template,
            file_name=f"MSA_Template_{project_data.get('name', 'Projeto')}.csv",
            mime="text/csv",
            key=f"download_template_{project_id}"
        )
        
        st.info("üí° Preencha o campo 'Medi√ß√£o' com os valores coletados e fa√ßa upload do arquivo preenchido.")
    
    # Upload dos dados MSA
    st.markdown("### üì§ Upload dos Dados MSA")
    
    msa_file = st.file_uploader(
        "Upload do arquivo com dados MSA",
        type=['csv', 'xlsx', 'xls'],
        key=f"msa_upload_{project_id}",
        help="Use o template gerado acima ou um arquivo com colunas: Operador, Pe√ßa, Repeti√ß√£o, Medi√ß√£o"
    )
    
    if msa_file is not None:
        try:
            # Ler arquivo
            if msa_file.name.endswith('.csv'):
                msa_df = pd.read_csv(msa_file)
            else:
                msa_df = pd.read_excel(msa_file)
            
            # Validar estrutura
            required_columns = ['Operador', 'Pe√ßa', 'Repeti√ß√£o', 'Medi√ß√£o']
            missing_columns = [col for col in required_columns if col not in msa_df.columns]
            
            if missing_columns:
                st.error(f"‚ùå Colunas obrigat√≥rias ausentes: {missing_columns}")
                return
            
            # Validar dados
            if msa_df['Medi√ß√£o'].isnull().any():
                st.warning("‚ö†Ô∏è Existem valores vazios na coluna 'Medi√ß√£o'")
                msa_df = msa_df.dropna(subset=['Medi√ß√£o'])
            
            # Converter Medi√ß√£o para num√©rico
            try:
                msa_df['Medi√ß√£o'] = pd.to_numeric(msa_df['Medi√ß√£o'])
            except:
                st.error("‚ùå A coluna 'Medi√ß√£o' deve conter apenas valores num√©ricos")
                return
            
            st.success(f"‚úÖ Dados MSA carregados: {len(msa_df)} medi√ß√µes")
            
            # Realizar an√°lise MSA
            st.markdown("### üìä An√°lise MSA")
            
            try:
                msa_results = perform_msa_analysis(msa_df)
                
                # Mostrar resultados
                col4, col5, col6 = st.columns(3)
                
                with col4:
                    rr_pct = msa_results['rr_percent']
                    st.metric("R&R (%)", f"{rr_pct:.1f}%")
                    
                    if rr_pct < 10:
                        st.success("‚úÖ Excelente")
                    elif rr_pct < 30:
                        st.warning("‚ö†Ô∏è Aceit√°vel")
                    else:
                        st.error("‚ùå Inadequado")
                
                with col5:
                    st.metric("Repetibilidade (%)", f"{msa_results['repeatability_percent']:.1f}%")
                
                with col6:
                    st.metric("Reprodutibilidade (%)", f"{msa_results['reproducibility_percent']:.1f}%")
                
                # Gr√°ficos MSA
                st.markdown("### üìà Gr√°ficos MSA")
                
                try:
                    fig_rr = create_msa_charts(msa_df, msa_results)
                    st.plotly_chart(fig_rr, use_container_width=True)
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erro ao criar gr√°ficos: {str(e)}")
                
                # Tabela ANOVA
                st.markdown("### üìã An√°lise de Vari√¢ncia (ANOVA)")
                
                anova_df = pd.DataFrame({
                    'Fonte de Varia√ß√£o': ['Repetibilidade', 'Reprodutibilidade', 'R&R', 'Pe√ßas', 'Total'],
                    'Vari√¢ncia': [
                        msa_results['repeatability_var'],
                        msa_results['reproducibility_var'],
                        msa_results['rr_var'],
                        msa_results['part_var'],
                        msa_results['total_var']
                    ],
                    'Desvio Padr√£o': [
                        np.sqrt(max(0, msa_results['repeatability_var'])),
                        np.sqrt(max(0, msa_results['reproducibility_var'])),
                        np.sqrt(max(0, msa_results['rr_var'])),
                        np.sqrt(max(0, msa_results['part_var'])),
                        np.sqrt(max(0, msa_results['total_var']))
                    ],
                    '% Contribui√ß√£o': [
                        msa_results['repeatability_percent'],
                        msa_results['reproducibility_percent'],
                        msa_results['rr_percent'],
                        msa_results['part_percent'],
                        100.0
                    ]
                })
                
                st.dataframe(anova_df, use_container_width=True)
                
                # Interpreta√ß√£o e recomenda√ß√µes
                st.markdown("### üéØ Interpreta√ß√£o e Recomenda√ß√µes")
                
                interpretation = "N/A"
                if rr_pct < 10:
                    st.success("""
                    ‚úÖ **Sistema de Medi√ß√£o Excelente**
                    
                    O sistema de medi√ß√£o √© adequado para o processo. A variabilidade R&R √© baixa e n√£o compromete a an√°lise do processo.
                    """)
                    interpretation = "Excelente"
                
                elif rr_pct < 30:
                    st.warning("""
                    ‚ö†Ô∏è **Sistema de Medi√ß√£o Aceit√°vel**
                    
                    O sistema pode ser usado, mas considere melhorias:
                    - Treinamento adicional dos operadores
                    - Calibra√ß√£o mais frequente dos equipamentos
                    - Revis√£o dos procedimentos de medi√ß√£o
                    """)
                    interpretation = "Aceit√°vel"
                
                else:
                    st.error("""
                    ‚ùå **Sistema de Medi√ß√£o Inadequado**
                    
                    O sistema precisa de melhorias significativas:
                    - Revisar completamente o procedimento de medi√ß√£o
                    - Substituir ou reparar equipamentos de medi√ß√£o
                    - Retreinar operadores
                    - Considerar automa√ß√£o da medi√ß√£o
                    """)
                    interpretation = "Inadequado"
                
                # Salvar resultados MSA
                if st.button("üíæ Salvar An√°lise MSA", key=f"save_msa_{project_id}"):
                    msa_summary = {
                        'analysis_date': datetime.now().isoformat(),
                        'num_operators': int(num_operators),
                        'num_parts': int(num_parts),
                        'num_trials': int(num_trials),
                        'total_measurements': len(msa_df),
                        'rr_percent': float(msa_results['rr_percent']),
                        'repeatability_percent': float(msa_results['repeatability_percent']),
                        'reproducibility_percent': float(msa_results['reproducibility_percent']),
                        'part_percent': float(msa_results['part_percent']),
                        'interpretation': interpretation
                    }
                    
                    # Salvar no Firebase
                    update_data = {
                        f'measure.msa.data': msa_summary,
                        f'measure.msa.completed': True,
                        f'measure.msa.updated_at': datetime.now().isoformat(),
                        'updated_at': datetime.now().isoformat()
                    }
                    
                    project_manager = ProjectManager()
                    
                    with st.spinner("üíæ Salvando..."):
                        try:
                            success = project_manager.update_project(project_id, update_data)
                            
                            if success:
                                st.success("‚úÖ An√°lise MSA salva!")
                                st.balloons()
                            else:
                                st.error("‚ùå Erro ao salvar")
                                
                        except Exception as e:
                            st.error(f"‚ùå Erro: {str(e)}")
                            
            except Exception as e:
                st.error(f"‚ùå Erro na an√°lise MSA: {str(e)}")
                        
        except Exception as e:
            st.error(f"‚ùå Erro ao processar arquivo: {str(e)}")


def perform_msa_analysis(df):
    """Realiza an√°lise MSA nos dados"""
    
    try:
        # Calcular m√©dias por operador e pe√ßa
        part_means = df.groupby('Pe√ßa')['Medi√ß√£o'].mean()
        grand_mean = df['Medi√ß√£o'].mean()
        
        # Calcular vari√¢ncias com verifica√ß√£o de valores v√°lidos
        # Repetibilidade (dentro do operador)
        repeatability_vars = df.groupby(['Operador', 'Pe√ßa'])['Medi√ß√£o'].var().dropna()
        repeatability_var = repeatability_vars.mean() if len(repeatability_vars) > 0 else 0
        
        # Reprodutibilidade (entre operadores)
        operator_part_means = df.groupby(['Operador', 'Pe√ßa'])['Medi√ß√£o'].mean().reset_index()
        reproducibility_vars = operator_part_means.groupby('Pe√ßa')['Medi√ß√£o'].var().dropna()
        reproducibility_var = reproducibility_vars.mean() if len(reproducibility_vars) > 0 else 0
        
        # Vari√¢ncia das pe√ßas
        part_var = part_means.var() if len(part_means) > 1 else 0
        
        # R&R
        rr_var = repeatability_var + reproducibility_var
        
        # Vari√¢ncia total
        total_var = df['Medi√ß√£o'].var()
        
        # Evitar divis√£o por zero
        if total_var <= 0:
            total_var = 1e-10
        
        # Converter para percentuais
        repeatability_percent = max(0, (repeatability_var / total_var) * 100)
        reproducibility_percent = max(0, (reproducibility_var / total_var) * 100)
        rr_percent = max(0, (rr_var / total_var) * 100)
        part_percent = max(0, (part_var / total_var) * 100)
        
        # Garantir que os percentuais n√£o excedam 100%
        total_percent = repeatability_percent + reproducibility_percent + part_percent
        if total_percent > 100:
            factor = 100 / total_percent
            repeatability_percent *= factor
            reproducibility_percent *= factor
            part_percent *= factor
            rr_percent = repeatability_percent + reproducibility_percent
        
        return {
            'repeatability_var': max(0, repeatability_var),
            'reproducibility_var': max(0, reproducibility_var),
            'rr_var': max(0, rr_var),
            'part_var': max(0, part_var),
            'total_var': max(0, total_var),
            'repeatability_percent': repeatability_percent,
            'reproducibility_percent': reproducibility_percent,
            'rr_percent': rr_percent,
            'part_percent': part_percent
        }
        
    except Exception as e:
        st.error(f"‚ùå Erro na an√°lise MSA: {str(e)}")
        # Retornar valores padr√£o em caso de erro
        return {
            'repeatability_var': 0,
            'reproducibility_var': 0,
            'rr_var': 0,
            'part_var': 0,
            'total_var': 1,
            'repeatability_percent': 0,
            'reproducibility_percent': 0,
            'rr_percent': 0,
            'part_percent': 100
        }


def create_msa_charts(df, results):
    """Cria gr√°ficos para an√°lise MSA"""
    
    try:
        # Gr√°fico de m√©dias por operador e pe√ßa
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('M√©dias por Operador e Pe√ßa', 'Ranges por Operador', 
                           'Distribui√ß√£o dos Dados', 'Contribui√ß√£o da Vari√¢ncia'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"type": "pie"}]]
        )
        
        # Gr√°fico 1: M√©dias por operador e pe√ßa
        for operator in df['Operador'].unique():
            operator_data = df[df['Operador'] == operator]
            means_by_part = operator_data.groupby('Pe√ßa')['Medi√ß√£o'].mean()
            
            fig.add_trace(
                go.Scatter(x=means_by_part.index, y=means_by_part.values, 
                          mode='lines+markers', name=str(operator)),
                row=1, col=1
            )
        
        # Gr√°fico 2: Ranges por operador
        ranges_by_operator = df.groupby(['Operador', 'Pe√ßa'])['Medi√ß√£o'].apply(lambda x: x.max() - x.min()).reset_index()
        
        for operator in ranges_by_operator['Operador'].unique():
            operator_ranges = ranges_by_operator[ranges_by_operator['Operador'] == operator]
            
            fig.add_trace(
                go.Scatter(x=operator_ranges['Pe√ßa'], y=operator_ranges['Medi√ß√£o'], 
                          mode='lines+markers', name=f"{operator} Range", showlegend=False),
                row=1, col=2
            )
        
        # Gr√°fico 3: Distribui√ß√£o dos dados
        fig.add_trace(
            go.Histogram(x=df['Medi√ß√£o'], nbinsx=20, name='Distribui√ß√£o', showlegend=False),
            row=2, col=1
        )
        
        # Gr√°fico 4: Pizza da contribui√ß√£o da vari√¢ncia
        labels = ['Repetibilidade', 'Reprodutibilidade', 'Pe√ßas']
        values = [results['repeatability_percent'], 
                  results['reproducibility_percent'],
                  results['part_percent']]
        
        # Filtrar valores v√°lidos
        valid_data = [(l, v) for l, v in zip(labels, values) if v > 0]
        if valid_data:
            valid_labels, valid_values = zip(*valid_data)
            
            fig.add_trace(
                go.Pie(labels=valid_labels, values=valid_values, name="Vari√¢ncia", showlegend=False),
                row=2, col=2
            )
        
        fig.update_layout(height=600, title_text="An√°lise MSA - Gr√°ficos de Diagn√≥stico")
        
        return fig
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao criar gr√°ficos MSA: {str(e)}")
        return go.Figure()


def show_measure_tools(project_data: Dict):
    """Fun√ß√£o principal para mostrar as ferramentas da fase Measure"""
    
    if not project_data:
        st.error("‚ùå Projeto n√£o encontrado")
        return
    
    # Menu de ferramentas
    st.markdown("### üîß Ferramentas da Fase Measure")
    
    tool_options = {
        "data_plan": "üìä Plano de Coleta de Dados",
        "file_upload": "üìÅ Upload e An√°lise de Dados", 
        "capability": "üìê Capacidade do Processo",
        "msa": "üéØ MSA - Sistema de Medi√ß√£o",
        "baseline": "üìà Baseline e M√©tricas CTQ"
    }
    
    # Verificar status das ferramentas
    measure_data = project_data.get('measure', {})
    
    # Usar selectbox para navega√ß√£o
    tool_names_with_status = []
    tool_keys = list(tool_options.keys())
    
    for key, name in tool_options.items():
        is_completed = measure_data.get(key, {}).get('completed', False)
        status_icon = "‚úÖ" if is_completed else "‚è≥"
        tool_names_with_status.append(f"{status_icon} {name}")
    
    selected_index = st.selectbox(
        "Selecione uma ferramenta:",
        range(len(tool_names_with_status)),
        format_func=lambda x: tool_names_with_status[x],
        key=f"measure_tool_selector_{project_data.get('id')}"
    )
    
    selected_tool = tool_keys[selected_index]
    
    st.divider()
    
    # Mostrar ferramenta selecionada
    if selected_tool == "data_plan":
        show_data_collection_plan(project_data)
    elif selected_tool == "file_upload":
        show_file_upload_analysis(project_data)
    elif selected_tool == "capability":
        show_process_capability(project_data)
    elif selected_tool == "msa":
        show_msa_analysis(project_data)
    elif selected_tool == "baseline":
        st.info("üöß Baseline e M√©tricas CTQ - Em desenvolvimento")
    
    # Progresso geral da fase Measure
    st.divider()
    st.markdown("### üìä Progresso da Fase Measure")
    
    total_tools = len(tool_options)
    completed_tools = sum(1 for tool_key in tool_options.keys() 
                        if measure_data.get(tool_key, {}).get('completed', False))
    
    progress = (completed_tools / total_tools) * 100
    
    col_prog1, col_prog2 = st.columns([3, 1])
    
    with col_prog1:
        st.progress(progress / 100)
        st.caption(f"{completed_tools}/{total_tools} ferramentas conclu√≠das ({progress:.1f}%)")
    
    with col_prog2:
        if progress == 100:
            st.success("üéâ Completo!")
        else:
            st.info(f"‚è≥ {progress:.0f}%")
    
    if progress == 100:
        st.success("üéâ **Parab√©ns! Fase Measure conclu√≠da com sucesso!**")
        st.info("‚ú® Voc√™ pode avan√ßar para a fase **Analyze** usando a navega√ß√£o das fases.")
